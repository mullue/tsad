{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly detection for clickstream data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection with DeepAR Timeseries forecasting\n",
    "\n",
    "We will use variables and dataframes that we stored at 1.EDA step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r urls css streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will divide our clikstream events by page. In other words, each page has its own clickstream timesereis. We can consider it as separated product sales in retail store. And we will predict the number of clicks in 10 minutes by referring to the number of visitors. To do this, we use the number of clicks as the target feature and the number of users as the dynamic feature.\n",
    "\n",
    "Change the data to the format that DeepAR algorithm use. The records in your input files should contain the following fields:\n",
    "\n",
    "- start—The start timestamp. A string with the format YYYY-MM-DD HH:MM:SS.\n",
    "- target—An array of floating-point values or integers that represent the time series. Here, we will use clickstream counts in 10 minutes for forecasting value.\n",
    "- dynamic_feat (optional)—An array of arrays of floating-point values or integers that represents the vector of custom feature time series. Here, we will use the number of visitors in 10 minutes for dynamic features.\n",
    "- cat (optional)—An array of categorical features that can be used to encode the groups that the record belongs to. We do not use categorical values in this example.\n",
    "\n",
    "```python\n",
    "# example:\n",
    "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, ...], \"dynamic_feat\": [[13, 14, 8, ...]]}\n",
    "```\n",
    "\n",
    "For more information regarding input/outpot format of DeepAR : https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html#deepar-inputoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for index, url in zip(range(len(urls)), urls):\n",
    "    r = css[css['url'] == url].set_index('timestamp').resample('10T')\n",
    "    l = {'start' : str(r.nunique().index[0]),\n",
    "         'target': list(r.sum()['clickstream_id'].values.astype('float')),\n",
    "         'dynamic_feat': [list(r.nunique()['user_session_id'].values.astype('float'))]\n",
    "        }\n",
    "    data.append(l)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the data in above format to json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "            \n",
    "write_dicts_to_file(\"train.json\", data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, upload this file to the S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-308961792850/deepar-clickstream/train.json'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "s3_bucket = sagemaker.Session().default_bucket()  # replace with an existing bucket if needed\n",
    "s3_prefix = 'deepar-clickstream'    # prefix used for all data stored within the bucket\n",
    "\n",
    "role = sagemaker.get_execution_role()             # IAM role to use by SageMaker\n",
    "\n",
    "train_s3 = sagemaker_session.upload_data(path='train.json', key_prefix=s3_prefix)\n",
    "train_s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"start\": \"2012-03-01 00:00:00\", \"target\": [24.0, 22.0, 20.0, 17.0, 15.0, 12.0, 15.0, 10.0, 14.0, 9....\n"
     ]
    }
   ],
   "source": [
    "import s3fs\n",
    "\n",
    "s3filesystem = s3fs.S3FileSystem()\n",
    "with s3filesystem.open(train_s3, 'rb') as fp:\n",
    "    print(fp.readline().decode(\"utf-8\")[:100] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SageMaker DeepAR Tranining\n",
    "\n",
    "Training a model is almost identical to using any other built-in algorithm. We need to define Estimator with algorhtim and hyperparameters and fit the model with the training data that we prepared above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "import datetime \n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "\n",
    "# we use 10 minutes frequency for the time series\n",
    "freq = datetime.timedelta(minutes=10)\n",
    "\n",
    "# we predict for 24 hours and use same context length with prediction length.\n",
    "prediction_length = 24 * 6\n",
    "context_length = 24 * 6\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='deepar-clickstream'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "    \"time_freq\": '10min',\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training will take about 20 minutes in c4.2xlarge instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-11 16:23:31 Starting - Starting the training job...\n",
      "2020-08-11 16:23:34 Starting - Launching requested ML instances.........\n",
      "2020-08-11 16:25:17 Starting - Preparing the instances for training......\n",
      "2020-08-11 16:26:26 Downloading - Downloading input data\n",
      "2020-08-11 16:26:26 Training - Downloading the training image...\n",
      "2020-08-11 16:26:48 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'144', u'epochs': u'400', u'time_freq': u'10min', u'context_length': u'144', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'144', u'time_freq': u'10min', u'context_length': u'144', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] [num_dynamic_feat=auto] `dynamic_feat` field was found in the file `/opt/ml/input/data/train/train.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] [num_dynamic_feat=auto] Inferred value of num_dynamic_feat=1 from dataset.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Training set statistics:\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Integer time series\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] number of time series: 16\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] number of observations: 34556\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] mean target length: 2159\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] min/mean/max target: 0.0/12.1908206968/477.0\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] mean abs(target): 12.1908206968\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] contains missing values: no\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Small number of time series. Doing 40 passes over dataset with prob 1.0 per epoch.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] nvidia-smi took: 0.0252349376678 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:51 INFO 139712694728512] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 2290.36808013916, \"sum\": 2290.36808013916, \"min\": 2290.36808013916}}, \"EndTime\": 1597163214.021548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163211.73025}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:54 INFO 139712694728512] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 3818.9961910247803, \"sum\": 3818.9961910247803, \"min\": 3818.9961910247803}}, \"EndTime\": 1597163215.549391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163214.021639}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:56 INFO 139712694728512] Epoch[0] Batch[0] avg_epoch_loss=4.127233\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=4.12723302841\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:58 INFO 139712694728512] Epoch[0] Batch[5] avg_epoch_loss=3.689773\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.68977308273\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:26:58 INFO 139712694728512] Epoch[0] Batch [5]#011Speed: 183.93 samples/sec#011loss=3.689773\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:00 INFO 139712694728512] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 4455.446004867554, \"sum\": 4455.446004867554, \"min\": 4455.446004867554}}, \"EndTime\": 1597163220.005088, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163215.549511}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:00 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=138.028643639 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:00 INFO 139712694728512] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.58199129105\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:00 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:00 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_2d681414-d44d-4736-900a-e40a032d7035-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 179.31008338928223, \"sum\": 179.31008338928223, \"min\": 179.31008338928223}}, \"EndTime\": 1597163220.185243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163220.005192}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:01 INFO 139712694728512] Epoch[1] Batch[0] avg_epoch_loss=3.360096\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=3.36009573936\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:02 INFO 139712694728512] Epoch[1] Batch[5] avg_epoch_loss=3.310484\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=3.3104839325\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:02 INFO 139712694728512] Epoch[1] Batch [5]#011Speed: 180.69 samples/sec#011loss=3.310484\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:04 INFO 139712694728512] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4044.545888900757, \"sum\": 4044.545888900757, \"min\": 4044.545888900757}}, \"EndTime\": 1597163224.229953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163220.185334}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:04 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.749154018 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:04 INFO 139712694728512] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.27420971394\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:04 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:04 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_a219546d-096c-4ef4-93e8-daab6d030dd0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 132.88116455078125, \"sum\": 132.88116455078125, \"min\": 132.88116455078125}}, \"EndTime\": 1597163224.363488, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163224.230045}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:05 INFO 139712694728512] Epoch[2] Batch[0] avg_epoch_loss=3.061816\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=3.06181573868\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:06 INFO 139712694728512] Epoch[2] Batch[5] avg_epoch_loss=3.076424\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=3.07642388344\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:06 INFO 139712694728512] Epoch[2] Batch [5]#011Speed: 179.80 samples/sec#011loss=3.076424\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] Epoch[2] Batch[10] avg_epoch_loss=3.055618\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=3.03065152168\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] Epoch[2] Batch [10]#011Speed: 176.13 samples/sec#011loss=3.030652\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4411.406993865967, \"sum\": 4411.406993865967, \"min\": 4411.406993865967}}, \"EndTime\": 1597163228.775057, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163224.363578}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.021071467 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=2, train loss <loss>=3.05561826446\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:08 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_95a5959c-492f-4e33-b35d-fe965d7359ef-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 143.06211471557617, \"sum\": 143.06211471557617, \"min\": 143.06211471557617}}, \"EndTime\": 1597163228.918783, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163228.775144}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:09 INFO 139712694728512] Epoch[3] Batch[0] avg_epoch_loss=2.952748\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.95274758339\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:11 INFO 139712694728512] Epoch[3] Batch[5] avg_epoch_loss=2.997583\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.99758267403\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:11 INFO 139712694728512] Epoch[3] Batch [5]#011Speed: 179.09 samples/sec#011loss=2.997583\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] Epoch[3] Batch[10] avg_epoch_loss=3.031796\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=3.07285223007\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] Epoch[3] Batch [10]#011Speed: 179.86 samples/sec#011loss=3.072852\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4397.244930267334, \"sum\": 4397.244930267334, \"min\": 4397.244930267334}}, \"EndTime\": 1597163233.316167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163228.918853}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.317052752 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=3, train loss <loss>=3.03179610859\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:13 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_58f16b8e-ac03-44e9-a74d-35b67db043fb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.83422660827637, \"sum\": 125.83422660827637, \"min\": 125.83422660827637}}, \"EndTime\": 1597163233.442591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163233.316256}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:14 INFO 139712694728512] Epoch[4] Batch[0] avg_epoch_loss=2.976892\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.97689247131\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:16 INFO 139712694728512] Epoch[4] Batch[5] avg_epoch_loss=2.850577\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.85057707628\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:16 INFO 139712694728512] Epoch[4] Batch [5]#011Speed: 180.45 samples/sec#011loss=2.850577\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:17 INFO 139712694728512] processed a total of 571 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3678.3950328826904, \"sum\": 3678.3950328826904, \"min\": 3678.3950328826904}}, \"EndTime\": 1597163237.121143, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163233.442677}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:17 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.225512866 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:17 INFO 139712694728512] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.85377457407\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:17 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:17 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_1a718800-5ef2-454f-957b-98995c90df74-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.42496490478516, \"sum\": 117.42496490478516, \"min\": 117.42496490478516}}, \"EndTime\": 1597163237.239216, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163237.121225}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:18 INFO 139712694728512] Epoch[5] Batch[0] avg_epoch_loss=2.687168\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.6871676445\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:19 INFO 139712694728512] Epoch[5] Batch[5] avg_epoch_loss=2.720136\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.72013616562\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:19 INFO 139712694728512] Epoch[5] Batch [5]#011Speed: 180.21 samples/sec#011loss=2.720136\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] Epoch[5] Batch[10] avg_epoch_loss=2.644081\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=2.55281572342\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] Epoch[5] Batch [10]#011Speed: 171.83 samples/sec#011loss=2.552816\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4451.977968215942, \"sum\": 4451.977968215942, \"min\": 4451.977968215942}}, \"EndTime\": 1597163241.691354, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163237.239307}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.266100851 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.64408141916\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:21 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_0dcb88d7-f925-4d9f-82e6-54bf371429bf-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 130.82194328308105, \"sum\": 130.82194328308105, \"min\": 130.82194328308105}}, \"EndTime\": 1597163241.822821, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163241.691441}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:22 INFO 139712694728512] Epoch[6] Batch[0] avg_epoch_loss=2.749756\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.74975585938\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:24 INFO 139712694728512] Epoch[6] Batch[5] avg_epoch_loss=2.638972\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.63897204399\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:24 INFO 139712694728512] Epoch[6] Batch [5]#011Speed: 178.29 samples/sec#011loss=2.638972\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:25 INFO 139712694728512] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4036.1931324005127, \"sum\": 4036.1931324005127, \"min\": 4036.1931324005127}}, \"EndTime\": 1597163245.859154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163241.822896}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:25 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.826215397 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:25 INFO 139712694728512] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.59308571815\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:25 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:25 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_22a0d78b-ba34-4ba8-8529-303dc46bfdfa-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.10889434814453, \"sum\": 116.10889434814453, \"min\": 116.10889434814453}}, \"EndTime\": 1597163245.97593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163245.859236}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:26 INFO 139712694728512] Epoch[7] Batch[0] avg_epoch_loss=2.720114\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.72011399269\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:28 INFO 139712694728512] Epoch[7] Batch[5] avg_epoch_loss=2.563823\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.56382314364\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:28 INFO 139712694728512] Epoch[7] Batch [5]#011Speed: 182.47 samples/sec#011loss=2.563823\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] Epoch[7] Batch[10] avg_epoch_loss=2.465939\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=2.34847817421\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] Epoch[7] Batch [10]#011Speed: 180.17 samples/sec#011loss=2.348478\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] processed a total of 668 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4340.487957000732, \"sum\": 4340.487957000732, \"min\": 4340.487957000732}}, \"EndTime\": 1597163250.316565, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163245.976007}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.895732025 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.46593906663\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:30 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_989baa61-93d6-4d79-b0aa-fddb0b1021eb-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.23709106445312, \"sum\": 117.23709106445312, \"min\": 117.23709106445312}}, \"EndTime\": 1597163250.434392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163250.316639}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:31 INFO 139712694728512] Epoch[8] Batch[0] avg_epoch_loss=2.336399\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.33639907837\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:32 INFO 139712694728512] Epoch[8] Batch[5] avg_epoch_loss=2.326855\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.32685518265\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:32 INFO 139712694728512] Epoch[8] Batch [5]#011Speed: 181.99 samples/sec#011loss=2.326855\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] Epoch[8] Batch[10] avg_epoch_loss=2.320564\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=2.31301403046\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] Epoch[8] Batch [10]#011Speed: 182.43 samples/sec#011loss=2.313014\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4315.945863723755, \"sum\": 4315.945863723755, \"min\": 4315.945863723755}}, \"EndTime\": 1597163254.750485, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163250.434468}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.685160853 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.32056374983\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:34 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_6068b2ba-5971-46d1-8d56-92d328664460-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 131.26897811889648, \"sum\": 131.26897811889648, \"min\": 131.26897811889648}}, \"EndTime\": 1597163254.882356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163254.750571}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:35 INFO 139712694728512] Epoch[9] Batch[0] avg_epoch_loss=2.597894\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.5978937149\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:37 INFO 139712694728512] Epoch[9] Batch[5] avg_epoch_loss=2.361195\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.36119500796\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:37 INFO 139712694728512] Epoch[9] Batch [5]#011Speed: 178.51 samples/sec#011loss=2.361195\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] Epoch[9] Batch[10] avg_epoch_loss=2.315898\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=2.26154198647\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] Epoch[9] Batch [10]#011Speed: 178.53 samples/sec#011loss=2.261542\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] processed a total of 707 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4776.336908340454, \"sum\": 4776.336908340454, \"min\": 4776.336908340454}}, \"EndTime\": 1597163259.65883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163254.882423}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.017261284 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.28360766172\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:39 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_c4095805-0f04-4803-a4d2-f8b5c48bcb3f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 139.84012603759766, \"sum\": 139.84012603759766, \"min\": 139.84012603759766}}, \"EndTime\": 1597163259.799273, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163259.65892}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:40 INFO 139712694728512] Epoch[10] Batch[0] avg_epoch_loss=2.157409\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.15740919113\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:42 INFO 139712694728512] Epoch[10] Batch[5] avg_epoch_loss=2.313635\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.31363455455\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:42 INFO 139712694728512] Epoch[10] Batch [5]#011Speed: 179.38 samples/sec#011loss=2.313635\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] Epoch[10] Batch[10] avg_epoch_loss=2.281540\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=2.2430267334\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] Epoch[10] Batch [10]#011Speed: 180.32 samples/sec#011loss=2.243027\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4389.110088348389, \"sum\": 4389.110088348389, \"min\": 4389.110088348389}}, \"EndTime\": 1597163264.18854, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163259.79936}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.228640097 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.28154009039\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:44 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_2bbbc85b-4859-4ee7-a6e7-8298ea521405-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 148.84114265441895, \"sum\": 148.84114265441895, \"min\": 148.84114265441895}}, \"EndTime\": 1597163264.337975, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163264.188627}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:45 INFO 139712694728512] Epoch[11] Batch[0] avg_epoch_loss=2.330943\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.3309431076\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:46 INFO 139712694728512] Epoch[11] Batch[5] avg_epoch_loss=2.203883\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.20388265451\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:46 INFO 139712694728512] Epoch[11] Batch [5]#011Speed: 179.40 samples/sec#011loss=2.203883\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] Epoch[11] Batch[10] avg_epoch_loss=2.183568\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=2.15919139385\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] Epoch[11] Batch [10]#011Speed: 180.49 samples/sec#011loss=2.159191\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4377.937078475952, \"sum\": 4377.937078475952, \"min\": 4377.937078475952}}, \"EndTime\": 1597163268.716075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163264.338062}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.35100407 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.18356844512\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:48 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_a33a7f67-46ce-4651-a427-9f39cc521dd0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.01791191101074, \"sum\": 118.01791191101074, \"min\": 118.01791191101074}}, \"EndTime\": 1597163268.834699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163268.716144}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:49 INFO 139712694728512] Epoch[12] Batch[0] avg_epoch_loss=2.155762\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.15576195717\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:51 INFO 139712694728512] Epoch[12] Batch[5] avg_epoch_loss=2.136740\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.1367401282\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:51 INFO 139712694728512] Epoch[12] Batch [5]#011Speed: 179.96 samples/sec#011loss=2.136740\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:52 INFO 139712694728512] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4028.9831161499023, \"sum\": 4028.9831161499023, \"min\": 4028.9831161499023}}, \"EndTime\": 1597163272.86383, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163268.834773}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:52 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.106341985 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:52 INFO 139712694728512] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.12231469154\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:52 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:52 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_570a89e3-3751-4801-9136-b9f8e632ced7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 126.94311141967773, \"sum\": 126.94311141967773, \"min\": 126.94311141967773}}, \"EndTime\": 1597163272.991422, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163272.863924}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:53 INFO 139712694728512] Epoch[13] Batch[0] avg_epoch_loss=2.084434\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:53 INFO 139712694728512] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.08443403244\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:55 INFO 139712694728512] Epoch[13] Batch[5] avg_epoch_loss=2.046479\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.04647884766\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:55 INFO 139712694728512] Epoch[13] Batch [5]#011Speed: 178.97 samples/sec#011loss=2.046479\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4025.02703666687, \"sum\": 4025.02703666687, \"min\": 4025.02703666687}}, \"EndTime\": 1597163277.016613, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163272.991525}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.763961119 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.02522864342\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_9dd3a2f3-6d9a-4ac7-ad59-d17bc672ad17-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 127.66504287719727, \"sum\": 127.66504287719727, \"min\": 127.66504287719727}}, \"EndTime\": 1597163277.144908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163277.016707}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] Epoch[14] Batch[0] avg_epoch_loss=1.979722\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=1.97972249985\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:59 INFO 139712694728512] Epoch[14] Batch[5] avg_epoch_loss=2.038990\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.03898994128\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:27:59 INFO 139712694728512] Epoch[14] Batch [5]#011Speed: 180.09 samples/sec#011loss=2.038990\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:01 INFO 139712694728512] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4048.8460063934326, \"sum\": 4048.8460063934326, \"min\": 4048.8460063934326}}, \"EndTime\": 1597163281.193887, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163277.144979}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:01 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.088739989 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:01 INFO 139712694728512] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.05711859465\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:01 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:02 INFO 139712694728512] Epoch[15] Batch[0] avg_epoch_loss=2.001461\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=2.00146055222\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:03 INFO 139712694728512] Epoch[15] Batch[5] avg_epoch_loss=1.956472\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=1.95647172133\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:03 INFO 139712694728512] Epoch[15] Batch [5]#011Speed: 181.33 samples/sec#011loss=1.956472\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:05 INFO 139712694728512] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4028.377056121826, \"sum\": 4028.377056121826, \"min\": 4028.377056121826}}, \"EndTime\": 1597163285.222841, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163281.193981}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:05 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.633636766 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:05 INFO 139712694728512] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=15, train loss <loss>=1.97117103338\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:05 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:05 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_d95b136c-99b8-4178-8f2b-94cc215268e6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 136.87896728515625, \"sum\": 136.87896728515625, \"min\": 136.87896728515625}}, \"EndTime\": 1597163285.36035, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163285.222934}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:06 INFO 139712694728512] Epoch[16] Batch[0] avg_epoch_loss=1.857983\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=1.85798323154\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:07 INFO 139712694728512] Epoch[16] Batch[5] avg_epoch_loss=1.939051\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=1.93905133009\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:07 INFO 139712694728512] Epoch[16] Batch [5]#011Speed: 181.99 samples/sec#011loss=1.939051\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:09 INFO 139712694728512] Epoch[16] Batch[10] avg_epoch_loss=1.952513\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=1.96866619587\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:09 INFO 139712694728512] Epoch[16] Batch [10]#011Speed: 178.36 samples/sec#011loss=1.968666\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:10 INFO 139712694728512] processed a total of 710 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4772.156000137329, \"sum\": 4772.156000137329, \"min\": 4772.156000137329}}, \"EndTime\": 1597163290.132641, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163285.360422}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:10 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.775505973 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:10 INFO 139712694728512] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=16, train loss <loss>=1.99683868885\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:10 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:11 INFO 139712694728512] Epoch[17] Batch[0] avg_epoch_loss=1.867600\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=1.86759996414\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:12 INFO 139712694728512] Epoch[17] Batch[5] avg_epoch_loss=1.889373\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=1.88937280575\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:12 INFO 139712694728512] Epoch[17] Batch [5]#011Speed: 180.78 samples/sec#011loss=1.889373\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:14 INFO 139712694728512] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4053.9660453796387, \"sum\": 4053.9660453796387, \"min\": 4053.9660453796387}}, \"EndTime\": 1597163294.187206, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163290.132736}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:14 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.398118611 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:14 INFO 139712694728512] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=17, train loss <loss>=1.90540349483\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:14 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:14 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_c3bf42a4-7afe-47d9-863d-c2a56021e46a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.76080322265625, \"sum\": 115.76080322265625, \"min\": 115.76080322265625}}, \"EndTime\": 1597163294.303677, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163294.187302}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:15 INFO 139712694728512] Epoch[18] Batch[0] avg_epoch_loss=1.918692\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=1.91869211197\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:16 INFO 139712694728512] Epoch[18] Batch[5] avg_epoch_loss=1.937403\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=1.93740328153\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:16 INFO 139712694728512] Epoch[18] Batch [5]#011Speed: 179.89 samples/sec#011loss=1.937403\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:18 INFO 139712694728512] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4019.5460319519043, \"sum\": 4019.5460319519043, \"min\": 4019.5460319519043}}, \"EndTime\": 1597163298.323356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163294.303748}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:18 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.992393247 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:18 INFO 139712694728512] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=18, train loss <loss>=1.90622090101\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:18 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:19 INFO 139712694728512] Epoch[19] Batch[0] avg_epoch_loss=1.946721\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=1.94672143459\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:20 INFO 139712694728512] Epoch[19] Batch[5] avg_epoch_loss=1.885214\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=1.88521422942\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:20 INFO 139712694728512] Epoch[19] Batch [5]#011Speed: 179.43 samples/sec#011loss=1.885214\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:22 INFO 139712694728512] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4019.2298889160156, \"sum\": 4019.2298889160156, \"min\": 4019.2298889160156}}, \"EndTime\": 1597163302.343254, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163298.32345}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:22 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.492341315 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:22 INFO 139712694728512] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=19, train loss <loss>=1.87030799389\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:22 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:22 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_5746c8b6-eab1-46ab-9f5f-74b72bdf454a-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.54407119750977, \"sum\": 125.54407119750977, \"min\": 125.54407119750977}}, \"EndTime\": 1597163302.469462, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163302.343347}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:23 INFO 139712694728512] Epoch[20] Batch[0] avg_epoch_loss=1.837368\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=1.8373683691\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:25 INFO 139712694728512] Epoch[20] Batch[5] avg_epoch_loss=1.804316\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=1.80431570609\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:25 INFO 139712694728512] Epoch[20] Batch [5]#011Speed: 180.28 samples/sec#011loss=1.804316\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:26 INFO 139712694728512] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4022.306203842163, \"sum\": 4022.306203842163, \"min\": 4022.306203842163}}, \"EndTime\": 1597163306.491915, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163302.469548}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:26 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.649734739 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:26 INFO 139712694728512] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=20, train loss <loss>=1.81939474344\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:26 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:26 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_f5ae0bfe-7c73-48bf-afc0-d9704d9bbfd8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.78402328491211, \"sum\": 117.78402328491211, \"min\": 117.78402328491211}}, \"EndTime\": 1597163306.610336, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163306.491995}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:27 INFO 139712694728512] Epoch[21] Batch[0] avg_epoch_loss=2.011372\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.0113723278\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:29 INFO 139712694728512] Epoch[21] Batch[5] avg_epoch_loss=1.856174\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=1.85617361466\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:29 INFO 139712694728512] Epoch[21] Batch [5]#011Speed: 181.62 samples/sec#011loss=1.856174\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] Epoch[21] Batch[10] avg_epoch_loss=1.800467\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=1.73361914158\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] Epoch[21] Batch [10]#011Speed: 179.75 samples/sec#011loss=1.733619\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4365.276098251343, \"sum\": 4365.276098251343, \"min\": 4365.276098251343}}, \"EndTime\": 1597163310.975768, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163306.610421}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.836524464 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] #quality_metric: host=algo-1, epoch=21, train loss <loss>=1.80046703599\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:30 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:31 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_7ef08b2f-3a1f-444a-b118-d3c7ddc0c6df-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 136.45482063293457, \"sum\": 136.45482063293457, \"min\": 136.45482063293457}}, \"EndTime\": 1597163311.112788, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163310.975852}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:31 INFO 139712694728512] Epoch[22] Batch[0] avg_epoch_loss=1.772418\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=1.77241754532\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:33 INFO 139712694728512] Epoch[22] Batch[5] avg_epoch_loss=1.815900\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=1.81589967012\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:33 INFO 139712694728512] Epoch[22] Batch [5]#011Speed: 180.95 samples/sec#011loss=1.815900\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:35 INFO 139712694728512] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3998.821020126343, \"sum\": 3998.821020126343, \"min\": 3998.821020126343}}, \"EndTime\": 1597163315.111743, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163311.112853}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:35 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.040811722 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:35 INFO 139712694728512] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=22, train loss <loss>=1.79167398214\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:35 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:35 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_84305a0d-fc58-4893-aea9-b6c7af4258ef-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 129.13012504577637, \"sum\": 129.13012504577637, \"min\": 129.13012504577637}}, \"EndTime\": 1597163315.241501, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163315.111836}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:36 INFO 139712694728512] Epoch[23] Batch[0] avg_epoch_loss=1.807313\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=1.80731320381\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:37 INFO 139712694728512] Epoch[23] Batch[5] avg_epoch_loss=1.827670\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=1.82766975959\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:37 INFO 139712694728512] Epoch[23] Batch [5]#011Speed: 180.74 samples/sec#011loss=1.827670\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:39 INFO 139712694728512] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4043.7400341033936, \"sum\": 4043.7400341033936, \"min\": 4043.7400341033936}}, \"EndTime\": 1597163319.285403, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163315.24159}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:39 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.027520967 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:39 INFO 139712694728512] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=23, train loss <loss>=1.79884693623\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:39 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:40 INFO 139712694728512] Epoch[24] Batch[0] avg_epoch_loss=1.776466\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=1.77646553516\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:41 INFO 139712694728512] Epoch[24] Batch[5] avg_epoch_loss=1.726582\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=1.72658177217\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:41 INFO 139712694728512] Epoch[24] Batch [5]#011Speed: 176.94 samples/sec#011loss=1.726582\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:43 INFO 139712694728512] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4065.6468868255615, \"sum\": 4065.6468868255615, \"min\": 4065.6468868255615}}, \"EndTime\": 1597163323.351688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163319.285497}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:43 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.6734612 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:43 INFO 139712694728512] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=24, train loss <loss>=1.71569652557\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:43 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:43 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_7d1d490c-adf3-42bb-8ac4-476a20c4913b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 126.56593322753906, \"sum\": 126.56593322753906, \"min\": 126.56593322753906}}, \"EndTime\": 1597163323.478883, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163323.351782}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:44 INFO 139712694728512] Epoch[25] Batch[0] avg_epoch_loss=1.691504\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=1.69150412083\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:46 INFO 139712694728512] Epoch[25] Batch[5] avg_epoch_loss=1.667353\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=1.6673531731\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:46 INFO 139712694728512] Epoch[25] Batch [5]#011Speed: 178.84 samples/sec#011loss=1.667353\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] Epoch[25] Batch[10] avg_epoch_loss=1.714085\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=1.77016210556\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] Epoch[25] Batch [10]#011Speed: 179.92 samples/sec#011loss=1.770162\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4407.782077789307, \"sum\": 4407.782077789307, \"min\": 4407.782077789307}}, \"EndTime\": 1597163327.886827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163323.47897}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.453199691 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] #quality_metric: host=algo-1, epoch=25, train loss <loss>=1.71408450603\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:47 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:48 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_5269fffc-d9f4-4123-9fe8-78d5b577718f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 119.20022964477539, \"sum\": 119.20022964477539, \"min\": 119.20022964477539}}, \"EndTime\": 1597163328.006675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163327.886914}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:48 INFO 139712694728512] Epoch[26] Batch[0] avg_epoch_loss=1.730890\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=1.730889678\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:50 INFO 139712694728512] Epoch[26] Batch[5] avg_epoch_loss=1.748908\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=1.74890830119\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:50 INFO 139712694728512] Epoch[26] Batch [5]#011Speed: 178.86 samples/sec#011loss=1.748908\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4028.640031814575, \"sum\": 4028.640031814575, \"min\": 4028.640031814575}}, \"EndTime\": 1597163332.035453, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163328.006752}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.643264404 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=26, train loss <loss>=1.69731612206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_5d4644e6-b55e-48d0-9cd3-bfef26599945-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 126.92594528198242, \"sum\": 126.92594528198242, \"min\": 126.92594528198242}}, \"EndTime\": 1597163332.163069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163332.035585}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] Epoch[27] Batch[0] avg_epoch_loss=1.750513\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=1.75051295757\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:54 INFO 139712694728512] Epoch[27] Batch[5] avg_epoch_loss=1.743376\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=1.74337571859\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:54 INFO 139712694728512] Epoch[27] Batch [5]#011Speed: 180.76 samples/sec#011loss=1.743376\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:56 INFO 139712694728512] processed a total of 602 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4058.2170486450195, \"sum\": 4058.2170486450195, \"min\": 4058.2170486450195}}, \"EndTime\": 1597163336.221446, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163332.163158}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:56 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.336073597 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:56 INFO 139712694728512] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=27, train loss <loss>=1.77237159014\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:56 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:57 INFO 139712694728512] Epoch[28] Batch[0] avg_epoch_loss=1.631096\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=1.6310955286\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:58 INFO 139712694728512] Epoch[28] Batch[5] avg_epoch_loss=1.648206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=1.64820591609\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:28:58 INFO 139712694728512] Epoch[28] Batch [5]#011Speed: 183.85 samples/sec#011loss=1.648206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:00 INFO 139712694728512] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3995.407819747925, \"sum\": 3995.407819747925, \"min\": 3995.407819747925}}, \"EndTime\": 1597163340.217394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163336.221539}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:00 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.676843382 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:00 INFO 139712694728512] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=28, train loss <loss>=1.65343469381\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:00 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:00 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_64d9f4b7-65ea-41dd-80b6-036e03d003dc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.33712387084961, \"sum\": 125.33712387084961, \"min\": 125.33712387084961}}, \"EndTime\": 1597163340.34338, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163340.217488}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:01 INFO 139712694728512] Epoch[29] Batch[0] avg_epoch_loss=1.676197\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=1.67619693279\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:02 INFO 139712694728512] Epoch[29] Batch[5] avg_epoch_loss=1.639945\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=1.63994475206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:02 INFO 139712694728512] Epoch[29] Batch [5]#011Speed: 181.82 samples/sec#011loss=1.639945\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] Epoch[29] Batch[10] avg_epoch_loss=1.591171\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=1.53264334202\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] Epoch[29] Batch [10]#011Speed: 183.81 samples/sec#011loss=1.532643\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4373.380184173584, \"sum\": 4373.380184173584, \"min\": 4373.380184173584}}, \"EndTime\": 1597163344.716919, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163340.343454}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.393601873 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=29, train loss <loss>=1.59117138386\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:04 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_78f7cb15-01f7-4c98-b1ec-7c95239ba94e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 122.63298034667969, \"sum\": 122.63298034667969, \"min\": 122.63298034667969}}, \"EndTime\": 1597163344.840145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163344.717006}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:05 INFO 139712694728512] Epoch[30] Batch[0] avg_epoch_loss=1.624872\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=1.62487220764\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:07 INFO 139712694728512] Epoch[30] Batch[5] avg_epoch_loss=1.633074\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=1.63307446241\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:07 INFO 139712694728512] Epoch[30] Batch [5]#011Speed: 179.80 samples/sec#011loss=1.633074\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:08 INFO 139712694728512] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4014.820098876953, \"sum\": 4014.820098876953, \"min\": 4014.820098876953}}, \"EndTime\": 1597163348.855086, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163344.840209}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:08 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.416250545 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:08 INFO 139712694728512] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=30, train loss <loss>=1.61917257309\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:08 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:09 INFO 139712694728512] Epoch[31] Batch[0] avg_epoch_loss=1.499224\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=1.4992235899\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:11 INFO 139712694728512] Epoch[31] Batch[5] avg_epoch_loss=1.583663\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=1.58366344372\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:11 INFO 139712694728512] Epoch[31] Batch [5]#011Speed: 177.24 samples/sec#011loss=1.583663\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] Epoch[31] Batch[10] avg_epoch_loss=1.556545\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=1.52400186062\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] Epoch[31] Batch [10]#011Speed: 180.66 samples/sec#011loss=1.524002\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4418.045997619629, \"sum\": 4418.045997619629, \"min\": 4418.045997619629}}, \"EndTime\": 1597163353.273832, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163348.855159}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.267696438 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=31, train loss <loss>=1.55654454231\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:13 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_ca618300-c142-4d67-b4fa-d3cebd40f692-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.05708503723145, \"sum\": 117.05708503723145, \"min\": 117.05708503723145}}, \"EndTime\": 1597163353.391542, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163353.27392}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:14 INFO 139712694728512] Epoch[32] Batch[0] avg_epoch_loss=1.584849\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=1.58484947681\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:15 INFO 139712694728512] Epoch[32] Batch[5] avg_epoch_loss=1.546789\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=1.5467890501\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:15 INFO 139712694728512] Epoch[32] Batch [5]#011Speed: 179.35 samples/sec#011loss=1.546789\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] Epoch[32] Batch[10] avg_epoch_loss=1.581619\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=1.62341601849\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] Epoch[32] Batch [10]#011Speed: 178.22 samples/sec#011loss=1.623416\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4396.347999572754, \"sum\": 4396.347999572754, \"min\": 4396.347999572754}}, \"EndTime\": 1597163357.788038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163353.391629}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.983740834 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=32, train loss <loss>=1.58161949028\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:17 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:18 INFO 139712694728512] Epoch[33] Batch[0] avg_epoch_loss=1.508749\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=1.50874888897\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:20 INFO 139712694728512] Epoch[33] Batch[5] avg_epoch_loss=1.549164\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=1.54916363955\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:20 INFO 139712694728512] Epoch[33] Batch [5]#011Speed: 178.05 samples/sec#011loss=1.549164\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] Epoch[33] Batch[10] avg_epoch_loss=1.541076\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=1.5313713789\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] Epoch[33] Batch [10]#011Speed: 179.45 samples/sec#011loss=1.531371\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4403.903007507324, \"sum\": 4403.903007507324, \"min\": 4403.903007507324}}, \"EndTime\": 1597163362.192513, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163357.788104}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.495947016 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=33, train loss <loss>=1.54107624834\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:22 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_bab50bdc-f58b-431c-a134-48c3fc2f2b0c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.91610717773438, \"sum\": 117.91610717773438, \"min\": 117.91610717773438}}, \"EndTime\": 1597163362.311022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163362.192594}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:23 INFO 139712694728512] Epoch[34] Batch[0] avg_epoch_loss=1.448733\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=1.44873332977\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:24 INFO 139712694728512] Epoch[34] Batch[5] avg_epoch_loss=1.525151\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=1.52515053749\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:24 INFO 139712694728512] Epoch[34] Batch [5]#011Speed: 181.24 samples/sec#011loss=1.525151\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] Epoch[34] Batch[10] avg_epoch_loss=1.460583\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=1.38310295343\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] Epoch[34] Batch [10]#011Speed: 177.77 samples/sec#011loss=1.383103\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4382.081985473633, \"sum\": 4382.081985473633, \"min\": 4382.081985473633}}, \"EndTime\": 1597163366.693255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163362.311103}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.555350239 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=34, train loss <loss>=1.46058345383\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:26 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_4cab98e4-afee-45bc-8f97-5fff0515cbef-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.47891998291016, \"sum\": 116.47891998291016, \"min\": 116.47891998291016}}, \"EndTime\": 1597163366.810395, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163366.693336}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:27 INFO 139712694728512] Epoch[35] Batch[0] avg_epoch_loss=1.649366\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=1.64936602116\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:29 INFO 139712694728512] Epoch[35] Batch[5] avg_epoch_loss=1.550828\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=1.55082770189\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:29 INFO 139712694728512] Epoch[35] Batch [5]#011Speed: 181.22 samples/sec#011loss=1.550828\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] Epoch[35] Batch[10] avg_epoch_loss=1.761211\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=2.01367061138\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] Epoch[35] Batch [10]#011Speed: 176.21 samples/sec#011loss=2.013671\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4397.040128707886, \"sum\": 4397.040128707886, \"min\": 4397.040128707886}}, \"EndTime\": 1597163371.207595, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163366.810484}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.186764033 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=35, train loss <loss>=1.76121084257\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:31 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:32 INFO 139712694728512] Epoch[36] Batch[0] avg_epoch_loss=1.552124\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=1.55212414265\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:33 INFO 139712694728512] Epoch[36] Batch[5] avg_epoch_loss=1.492692\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=1.4926923116\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:33 INFO 139712694728512] Epoch[36] Batch [5]#011Speed: 181.34 samples/sec#011loss=1.492692\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] Epoch[36] Batch[10] avg_epoch_loss=1.575852\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=1.67564349174\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] Epoch[36] Batch [10]#011Speed: 179.23 samples/sec#011loss=1.675643\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4375.821828842163, \"sum\": 4375.821828842163, \"min\": 4375.821828842163}}, \"EndTime\": 1597163375.58397, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163371.207685}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.367623984 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=36, train loss <loss>=1.57585193894\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:35 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:36 INFO 139712694728512] Epoch[37] Batch[0] avg_epoch_loss=1.712724\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=1.71272420883\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:38 INFO 139712694728512] Epoch[37] Batch[5] avg_epoch_loss=1.530256\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=1.53025555611\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:38 INFO 139712694728512] Epoch[37] Batch [5]#011Speed: 180.92 samples/sec#011loss=1.530256\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] Epoch[37] Batch[10] avg_epoch_loss=1.475806\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=1.41046651602\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] Epoch[37] Batch [10]#011Speed: 177.89 samples/sec#011loss=1.410467\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4385.026931762695, \"sum\": 4385.026931762695, \"min\": 4385.026931762695}}, \"EndTime\": 1597163379.969553, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163375.584049}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.631476761 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=37, train loss <loss>=1.47580599243\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:39 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:40 INFO 139712694728512] Epoch[38] Batch[0] avg_epoch_loss=1.826396\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=1.82639575005\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:42 INFO 139712694728512] Epoch[38] Batch[5] avg_epoch_loss=1.578422\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=1.5784222285\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:42 INFO 139712694728512] Epoch[38] Batch [5]#011Speed: 179.79 samples/sec#011loss=1.578422\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:43 INFO 139712694728512] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4010.8108520507812, \"sum\": 4010.8108520507812, \"min\": 4010.8108520507812}}, \"EndTime\": 1597163383.980873, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163379.969633}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:43 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=159.314708101 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:43 INFO 139712694728512] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=38, train loss <loss>=1.54578331709\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:43 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:44 INFO 139712694728512] Epoch[39] Batch[0] avg_epoch_loss=1.398301\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=1.39830136299\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:46 INFO 139712694728512] Epoch[39] Batch[5] avg_epoch_loss=1.456881\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=1.45688052972\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:46 INFO 139712694728512] Epoch[39] Batch [5]#011Speed: 179.25 samples/sec#011loss=1.456881\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] Epoch[39] Batch[10] avg_epoch_loss=1.515902\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=1.58672707081\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] Epoch[39] Batch [10]#011Speed: 181.74 samples/sec#011loss=1.586727\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4375.993967056274, \"sum\": 4375.993967056274, \"min\": 4375.993967056274}}, \"EndTime\": 1597163388.35744, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163383.980957}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.759866232 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=39, train loss <loss>=1.51590168476\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:48 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:49 INFO 139712694728512] Epoch[40] Batch[0] avg_epoch_loss=1.524685\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=1.5246847868\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:50 INFO 139712694728512] Epoch[40] Batch[5] avg_epoch_loss=1.412396\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=1.41239575545\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:50 INFO 139712694728512] Epoch[40] Batch [5]#011Speed: 178.65 samples/sec#011loss=1.412396\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] Epoch[40] Batch[10] avg_epoch_loss=1.375802\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=1.33188853264\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] Epoch[40] Batch [10]#011Speed: 179.21 samples/sec#011loss=1.331889\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4427.613973617554, \"sum\": 4427.613973617554, \"min\": 4427.613973617554}}, \"EndTime\": 1597163392.785578, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163388.357527}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.286160851 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=40, train loss <loss>=1.37580156326\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:52 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_3e6f89c1-2055-4c18-b296-cb88b5c0839d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 124.1459846496582, \"sum\": 124.1459846496582, \"min\": 124.1459846496582}}, \"EndTime\": 1597163392.910322, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163392.785664}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:53 INFO 139712694728512] Epoch[41] Batch[0] avg_epoch_loss=1.520131\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:53 INFO 139712694728512] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=1.52013063431\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:55 INFO 139712694728512] Epoch[41] Batch[5] avg_epoch_loss=1.452071\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=1.45207101107\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:55 INFO 139712694728512] Epoch[41] Batch [5]#011Speed: 178.52 samples/sec#011loss=1.452071\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] Epoch[41] Batch[10] avg_epoch_loss=1.439204\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=1.4237641573\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] Epoch[41] Batch [10]#011Speed: 174.07 samples/sec#011loss=1.423764\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4451.758146286011, \"sum\": 4451.758146286011, \"min\": 4451.758146286011}}, \"EndTime\": 1597163397.362248, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163392.91042}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.353415223 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=41, train loss <loss>=1.43920425935\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:57 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:58 INFO 139712694728512] Epoch[42] Batch[0] avg_epoch_loss=1.405000\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:29:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=1.40500044823\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:00 INFO 139712694728512] Epoch[42] Batch[5] avg_epoch_loss=1.399632\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=1.39963171879\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:00 INFO 139712694728512] Epoch[42] Batch [5]#011Speed: 179.58 samples/sec#011loss=1.399632\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:01 INFO 139712694728512] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4146.666049957275, \"sum\": 4146.666049957275, \"min\": 4146.666049957275}}, \"EndTime\": 1597163401.509423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163397.362333}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:01 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.130202149 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:01 INFO 139712694728512] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=42, train loss <loss>=1.43448437452\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:01 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:02 INFO 139712694728512] Epoch[43] Batch[0] avg_epoch_loss=1.368360\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=1.36835956573\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:04 INFO 139712694728512] Epoch[43] Batch[5] avg_epoch_loss=1.431904\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=1.43190395832\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:04 INFO 139712694728512] Epoch[43] Batch [5]#011Speed: 181.16 samples/sec#011loss=1.431904\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:05 INFO 139712694728512] processed a total of 605 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4067.434072494507, \"sum\": 4067.434072494507, \"min\": 4067.434072494507}}, \"EndTime\": 1597163405.577438, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163401.509516}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:05 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.737968013 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:05 INFO 139712694728512] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=43, train loss <loss>=1.44989435673\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:05 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:06 INFO 139712694728512] Epoch[44] Batch[0] avg_epoch_loss=1.480110\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=1.48011028767\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:08 INFO 139712694728512] Epoch[44] Batch[5] avg_epoch_loss=1.364804\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=1.36480404933\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:08 INFO 139712694728512] Epoch[44] Batch [5]#011Speed: 179.51 samples/sec#011loss=1.364804\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:09 INFO 139712694728512] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4033.5819721221924, \"sum\": 4033.5819721221924, \"min\": 4033.5819721221924}}, \"EndTime\": 1597163409.611652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163405.577516}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:09 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.456407585 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:09 INFO 139712694728512] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=44, train loss <loss>=1.38106694221\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:09 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:10 INFO 139712694728512] Epoch[45] Batch[0] avg_epoch_loss=1.216845\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=1.21684527397\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:12 INFO 139712694728512] Epoch[45] Batch[5] avg_epoch_loss=1.394069\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=1.39406861862\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:12 INFO 139712694728512] Epoch[45] Batch [5]#011Speed: 174.52 samples/sec#011loss=1.394069\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] Epoch[45] Batch[10] avg_epoch_loss=1.354066\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=1.30606215\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] Epoch[45] Batch [10]#011Speed: 181.46 samples/sec#011loss=1.306062\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4439.189910888672, \"sum\": 4439.189910888672, \"min\": 4439.189910888672}}, \"EndTime\": 1597163414.051419, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163409.611748}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.247523167 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=45, train loss <loss>=1.35406567834\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:14 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_f09735f9-776d-4b0c-9183-73fb8c5059e7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.99396705627441, \"sum\": 125.99396705627441, \"min\": 125.99396705627441}}, \"EndTime\": 1597163414.178041, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163414.051531}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:15 INFO 139712694728512] Epoch[46] Batch[0] avg_epoch_loss=1.368162\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=1.36816227436\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:16 INFO 139712694728512] Epoch[46] Batch[5] avg_epoch_loss=1.356711\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=1.35671114922\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:16 INFO 139712694728512] Epoch[46] Batch [5]#011Speed: 180.41 samples/sec#011loss=1.356711\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:18 INFO 139712694728512] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4015.7859325408936, \"sum\": 4015.7859325408936, \"min\": 4015.7859325408936}}, \"EndTime\": 1597163418.193989, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163414.178128}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:18 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.618587591 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:18 INFO 139712694728512] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=46, train loss <loss>=1.3628446579\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:18 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:19 INFO 139712694728512] Epoch[47] Batch[0] avg_epoch_loss=1.356142\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=1.35614180565\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:20 INFO 139712694728512] Epoch[47] Batch[5] avg_epoch_loss=1.400689\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=1.40068920453\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:20 INFO 139712694728512] Epoch[47] Batch [5]#011Speed: 180.75 samples/sec#011loss=1.400689\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] Epoch[47] Batch[10] avg_epoch_loss=1.339044\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=1.26507031918\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] Epoch[47] Batch [10]#011Speed: 180.11 samples/sec#011loss=1.265070\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4367.1228885650635, \"sum\": 4367.1228885650635, \"min\": 4367.1228885650635}}, \"EndTime\": 1597163422.56168, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163418.194083}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.919414524 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=47, train loss <loss>=1.33904425664\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:22 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_b530aa93-ed3c-4a7a-bea8-6afac8845726-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.34795570373535, \"sum\": 117.34795570373535, \"min\": 117.34795570373535}}, \"EndTime\": 1597163422.679616, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163422.561765}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:23 INFO 139712694728512] Epoch[48] Batch[0] avg_epoch_loss=1.397707\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=1.39770662785\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:25 INFO 139712694728512] Epoch[48] Batch[5] avg_epoch_loss=1.373247\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=1.37324680885\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:25 INFO 139712694728512] Epoch[48] Batch [5]#011Speed: 181.88 samples/sec#011loss=1.373247\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] Epoch[48] Batch[10] avg_epoch_loss=1.387421\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=1.40443012714\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] Epoch[48] Batch [10]#011Speed: 180.06 samples/sec#011loss=1.404430\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4344.897985458374, \"sum\": 4344.897985458374, \"min\": 4344.897985458374}}, \"EndTime\": 1597163427.024652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163422.679696}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.207487873 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=48, train loss <loss>=1.38742104444\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] Epoch[49] Batch[0] avg_epoch_loss=1.363390\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=1.36339044571\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:29 INFO 139712694728512] Epoch[49] Batch[5] avg_epoch_loss=1.355384\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=1.35538440943\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:29 INFO 139712694728512] Epoch[49] Batch [5]#011Speed: 183.47 samples/sec#011loss=1.355384\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] Epoch[49] Batch[10] avg_epoch_loss=1.389918\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=1.43135797977\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] Epoch[49] Batch [10]#011Speed: 178.63 samples/sec#011loss=1.431358\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4368.973016738892, \"sum\": 4368.973016738892, \"min\": 4368.973016738892}}, \"EndTime\": 1597163431.394156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163427.02474}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.459143951 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=49, train loss <loss>=1.38991785049\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:31 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:32 INFO 139712694728512] Epoch[50] Batch[0] avg_epoch_loss=1.534826\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=1.53482615948\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:33 INFO 139712694728512] Epoch[50] Batch[5] avg_epoch_loss=1.286417\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=1.2864172856\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:33 INFO 139712694728512] Epoch[50] Batch [5]#011Speed: 180.86 samples/sec#011loss=1.286417\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] Epoch[50] Batch[10] avg_epoch_loss=1.553364\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=1.87369990349\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] Epoch[50] Batch [10]#011Speed: 179.45 samples/sec#011loss=1.873700\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4362.661838531494, \"sum\": 4362.661838531494, \"min\": 4362.661838531494}}, \"EndTime\": 1597163435.757391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163431.394229}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.29969897 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=50, train loss <loss>=1.5533639301\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:35 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:36 INFO 139712694728512] Epoch[51] Batch[0] avg_epoch_loss=1.341982\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=1.34198188782\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:38 INFO 139712694728512] Epoch[51] Batch[5] avg_epoch_loss=1.377822\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=1.37782156467\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:38 INFO 139712694728512] Epoch[51] Batch [5]#011Speed: 180.73 samples/sec#011loss=1.377822\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] Epoch[51] Batch[10] avg_epoch_loss=1.307290\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=1.22265278101\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] Epoch[51] Batch [10]#011Speed: 179.02 samples/sec#011loss=1.222653\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4392.7600383758545, \"sum\": 4392.7600383758545, \"min\": 4392.7600383758545}}, \"EndTime\": 1597163440.150712, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163435.757473}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.787945451 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=51, train loss <loss>=1.30729029937\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:40 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_956c746e-aff5-4e41-bd8b-fbae19335fc3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 115.27013778686523, \"sum\": 115.27013778686523, \"min\": 115.27013778686523}}, \"EndTime\": 1597163440.266637, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163440.150792}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:41 INFO 139712694728512] Epoch[52] Batch[0] avg_epoch_loss=1.250851\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=1.25085103512\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:42 INFO 139712694728512] Epoch[52] Batch[5] avg_epoch_loss=1.344100\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=1.34409993887\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:42 INFO 139712694728512] Epoch[52] Batch [5]#011Speed: 177.75 samples/sec#011loss=1.344100\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] Epoch[52] Batch[10] avg_epoch_loss=1.329331\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=1.31160886288\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] Epoch[52] Batch [10]#011Speed: 179.63 samples/sec#011loss=1.311609\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4442.2619342803955, \"sum\": 4442.2619342803955, \"min\": 4442.2619342803955}}, \"EndTime\": 1597163444.709062, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163440.266724}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.018981124 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=52, train loss <loss>=1.32933126796\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:44 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:45 INFO 139712694728512] Epoch[53] Batch[0] avg_epoch_loss=1.459200\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=1.4592000246\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:47 INFO 139712694728512] Epoch[53] Batch[5] avg_epoch_loss=1.370804\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:47 INFO 139712694728512] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=1.37080409129\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:47 INFO 139712694728512] Epoch[53] Batch [5]#011Speed: 176.24 samples/sec#011loss=1.370804\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:48 INFO 139712694728512] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4036.80682182312, \"sum\": 4036.80682182312, \"min\": 4036.80682182312}}, \"EndTime\": 1597163448.746405, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163444.709144}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:48 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.306662532 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:48 INFO 139712694728512] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=53, train loss <loss>=1.3312505722\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:48 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:49 INFO 139712694728512] Epoch[54] Batch[0] avg_epoch_loss=1.275521\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=1.27552127838\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:51 INFO 139712694728512] Epoch[54] Batch[5] avg_epoch_loss=1.340356\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=1.34035555522\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:51 INFO 139712694728512] Epoch[54] Batch [5]#011Speed: 181.27 samples/sec#011loss=1.340356\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:52 INFO 139712694728512] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4053.230047225952, \"sum\": 4053.230047225952, \"min\": 4053.230047225952}}, \"EndTime\": 1597163452.800175, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163448.746495}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:52 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.179782033 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:52 INFO 139712694728512] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=54, train loss <loss>=1.32401294708\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:52 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:53 INFO 139712694728512] Epoch[55] Batch[0] avg_epoch_loss=1.106425\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:53 INFO 139712694728512] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=1.10642492771\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:55 INFO 139712694728512] Epoch[55] Batch[5] avg_epoch_loss=1.268793\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=1.26879270871\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:55 INFO 139712694728512] Epoch[55] Batch [5]#011Speed: 180.31 samples/sec#011loss=1.268793\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:56 INFO 139712694728512] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4018.983840942383, \"sum\": 4018.983840942383, \"min\": 4018.983840942383}}, \"EndTime\": 1597163456.819723, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163452.800269}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:56 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.267573687 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:56 INFO 139712694728512] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=55, train loss <loss>=1.22875013947\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:56 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:56 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_99021938-95fa-4d13-92e8-e1611339c377-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 135.98203659057617, \"sum\": 135.98203659057617, \"min\": 135.98203659057617}}, \"EndTime\": 1597163456.956413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163456.819815}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:57 INFO 139712694728512] Epoch[56] Batch[0] avg_epoch_loss=1.204980\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=1.20497953892\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:59 INFO 139712694728512] Epoch[56] Batch[5] avg_epoch_loss=1.299524\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=1.29952357213\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:30:59 INFO 139712694728512] Epoch[56] Batch [5]#011Speed: 182.19 samples/sec#011loss=1.299524\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:00 INFO 139712694728512] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3994.6727752685547, \"sum\": 3994.6727752685547, \"min\": 3994.6727752685547}}, \"EndTime\": 1597163460.95124, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163456.956494}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:00 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=160.208066318 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:00 INFO 139712694728512] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=56, train loss <loss>=1.29489653111\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:00 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:01 INFO 139712694728512] Epoch[57] Batch[0] avg_epoch_loss=1.341421\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=1.34142076969\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:03 INFO 139712694728512] Epoch[57] Batch[5] avg_epoch_loss=1.285565\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=1.28556549549\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:03 INFO 139712694728512] Epoch[57] Batch [5]#011Speed: 178.72 samples/sec#011loss=1.285565\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:05 INFO 139712694728512] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4086.5190029144287, \"sum\": 4086.5190029144287, \"min\": 4086.5190029144287}}, \"EndTime\": 1597163465.038349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163460.95133}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:05 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.489970134 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:05 INFO 139712694728512] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=57, train loss <loss>=1.30081298351\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:05 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:05 INFO 139712694728512] Epoch[58] Batch[0] avg_epoch_loss=1.321017\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=1.32101714611\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:07 INFO 139712694728512] Epoch[58] Batch[5] avg_epoch_loss=1.282396\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=1.28239641587\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:07 INFO 139712694728512] Epoch[58] Batch [5]#011Speed: 180.79 samples/sec#011loss=1.282396\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] Epoch[58] Batch[10] avg_epoch_loss=1.270159\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=1.25547301769\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] Epoch[58] Batch [10]#011Speed: 179.93 samples/sec#011loss=1.255473\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4418.462038040161, \"sum\": 4418.462038040161, \"min\": 4418.462038040161}}, \"EndTime\": 1597163469.457382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163465.038441}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.332168522 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=58, train loss <loss>=1.27015850761\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:09 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:10 INFO 139712694728512] Epoch[59] Batch[0] avg_epoch_loss=1.367780\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=1.36778008938\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:12 INFO 139712694728512] Epoch[59] Batch[5] avg_epoch_loss=1.343926\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=1.34392623107\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:12 INFO 139712694728512] Epoch[59] Batch [5]#011Speed: 179.53 samples/sec#011loss=1.343926\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:13 INFO 139712694728512] processed a total of 634 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4016.770839691162, \"sum\": 4016.770839691162, \"min\": 4016.770839691162}}, \"EndTime\": 1597163473.474677, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163469.457469}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:13 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.83292763 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:13 INFO 139712694728512] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=59, train loss <loss>=1.29621552229\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:13 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:14 INFO 139712694728512] Epoch[60] Batch[0] avg_epoch_loss=1.271792\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=1.27179169655\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:16 INFO 139712694728512] Epoch[60] Batch[5] avg_epoch_loss=1.290940\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=1.29094018539\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:16 INFO 139712694728512] Epoch[60] Batch [5]#011Speed: 182.55 samples/sec#011loss=1.290940\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:17 INFO 139712694728512] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3999.476909637451, \"sum\": 3999.476909637451, \"min\": 3999.476909637451}}, \"EndTime\": 1597163477.474714, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163473.474772}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:17 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.766024931 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:17 INFO 139712694728512] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=60, train loss <loss>=1.30617083311\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:17 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:18 INFO 139712694728512] Epoch[61] Batch[0] avg_epoch_loss=1.394476\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=1.39447557926\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:20 INFO 139712694728512] Epoch[61] Batch[5] avg_epoch_loss=1.232654\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=1.23265405496\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:20 INFO 139712694728512] Epoch[61] Batch [5]#011Speed: 183.09 samples/sec#011loss=1.232654\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] Epoch[61] Batch[10] avg_epoch_loss=1.151326\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=1.05373292267\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] Epoch[61] Batch [10]#011Speed: 182.67 samples/sec#011loss=1.053733\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4304.563999176025, \"sum\": 4304.563999176025, \"min\": 4304.563999176025}}, \"EndTime\": 1597163481.779819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163477.474797}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.068915647 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=61, train loss <loss>=1.15132626756\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:21 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_037a5098-615f-4685-95f8-e400c4a80769-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.0450611114502, \"sum\": 125.0450611114502, \"min\": 125.0450611114502}}, \"EndTime\": 1597163481.90548, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163481.779906}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:22 INFO 139712694728512] Epoch[62] Batch[0] avg_epoch_loss=1.538570\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=1.53857004642\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:24 INFO 139712694728512] Epoch[62] Batch[5] avg_epoch_loss=1.447206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=1.44720582167\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:24 INFO 139712694728512] Epoch[62] Batch [5]#011Speed: 182.91 samples/sec#011loss=1.447206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:25 INFO 139712694728512] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3972.5308418273926, \"sum\": 3972.5308418273926, \"min\": 3972.5308418273926}}, \"EndTime\": 1597163485.878154, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163481.905553}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:25 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.080249815 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:25 INFO 139712694728512] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=62, train loss <loss>=1.46461036205\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:25 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:26 INFO 139712694728512] Epoch[63] Batch[0] avg_epoch_loss=1.367825\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=1.36782467365\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:28 INFO 139712694728512] Epoch[63] Batch[5] avg_epoch_loss=1.324417\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=1.32441685597\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:28 INFO 139712694728512] Epoch[63] Batch [5]#011Speed: 182.28 samples/sec#011loss=1.324417\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:29 INFO 139712694728512] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3985.239028930664, \"sum\": 3985.239028930664, \"min\": 3985.239028930664}}, \"EndTime\": 1597163489.86398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163485.878248}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:29 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=160.336472051 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:29 INFO 139712694728512] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=63, train loss <loss>=1.3046667695\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:29 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:30 INFO 139712694728512] Epoch[64] Batch[0] avg_epoch_loss=1.337985\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:30 INFO 139712694728512] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=1.33798539639\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:32 INFO 139712694728512] Epoch[64] Batch[5] avg_epoch_loss=1.315575\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=1.31557484468\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:32 INFO 139712694728512] Epoch[64] Batch [5]#011Speed: 180.53 samples/sec#011loss=1.315575\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:33 INFO 139712694728512] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4039.5500659942627, \"sum\": 4039.5500659942627, \"min\": 4039.5500659942627}}, \"EndTime\": 1597163493.904075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163489.864071}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:33 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.180724482 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:33 INFO 139712694728512] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=64, train loss <loss>=1.29064188004\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:33 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:34 INFO 139712694728512] Epoch[65] Batch[0] avg_epoch_loss=1.262853\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:34 INFO 139712694728512] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=1.26285290718\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:36 INFO 139712694728512] Epoch[65] Batch[5] avg_epoch_loss=1.259388\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=1.25938779116\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:36 INFO 139712694728512] Epoch[65] Batch [5]#011Speed: 181.24 samples/sec#011loss=1.259388\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] Epoch[65] Batch[10] avg_epoch_loss=1.225546\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=1.18493629694\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] Epoch[65] Batch [10]#011Speed: 179.85 samples/sec#011loss=1.184936\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4413.931131362915, \"sum\": 4413.931131362915, \"min\": 4413.931131362915}}, \"EndTime\": 1597163498.318583, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163493.904168}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.483337196 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=65, train loss <loss>=1.22554620288\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:38 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:39 INFO 139712694728512] Epoch[66] Batch[0] avg_epoch_loss=1.489364\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=1.48936414719\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:40 INFO 139712694728512] Epoch[66] Batch[5] avg_epoch_loss=1.199244\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=1.19924406211\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:40 INFO 139712694728512] Epoch[66] Batch [5]#011Speed: 180.04 samples/sec#011loss=1.199244\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:42 INFO 139712694728512] Epoch[66] Batch[10] avg_epoch_loss=1.225120\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=1.25617105961\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:42 INFO 139712694728512] Epoch[66] Batch [10]#011Speed: 178.61 samples/sec#011loss=1.256171\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:43 INFO 139712694728512] processed a total of 706 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4837.048053741455, \"sum\": 4837.048053741455, \"min\": 4837.048053741455}}, \"EndTime\": 1597163503.156191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163498.31867}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:43 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=145.952745511 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:43 INFO 139712694728512] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=66, train loss <loss>=1.30208336314\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:43 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:43 INFO 139712694728512] Epoch[67] Batch[0] avg_epoch_loss=1.139314\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=1.13931429386\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:45 INFO 139712694728512] Epoch[67] Batch[5] avg_epoch_loss=1.246722\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=1.24672158559\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:45 INFO 139712694728512] Epoch[67] Batch [5]#011Speed: 183.78 samples/sec#011loss=1.246722\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:47 INFO 139712694728512] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4019.304037094116, \"sum\": 4019.304037094116, \"min\": 4019.304037094116}}, \"EndTime\": 1597163507.176114, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163503.156283}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:47 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.728741704 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:47 INFO 139712694728512] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:47 INFO 139712694728512] #quality_metric: host=algo-1, epoch=67, train loss <loss>=1.29459139109\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:47 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:48 INFO 139712694728512] Epoch[68] Batch[0] avg_epoch_loss=1.311506\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=1.31150591373\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:49 INFO 139712694728512] Epoch[68] Batch[5] avg_epoch_loss=1.239005\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=1.23900477091\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:49 INFO 139712694728512] Epoch[68] Batch [5]#011Speed: 181.63 samples/sec#011loss=1.239005\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] Epoch[68] Batch[10] avg_epoch_loss=1.189471\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=1.13003064394\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] Epoch[68] Batch [10]#011Speed: 178.71 samples/sec#011loss=1.130031\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4397.356986999512, \"sum\": 4397.356986999512, \"min\": 4397.356986999512}}, \"EndTime\": 1597163511.574023, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163507.176207}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.948846207 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=68, train loss <loss>=1.18947107684\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:51 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:52 INFO 139712694728512] Epoch[69] Batch[0] avg_epoch_loss=1.347351\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=1.34735059738\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:54 INFO 139712694728512] Epoch[69] Batch[5] avg_epoch_loss=1.254179\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=1.25417862336\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:54 INFO 139712694728512] Epoch[69] Batch [5]#011Speed: 177.02 samples/sec#011loss=1.254179\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:55 INFO 139712694728512] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4077.932834625244, \"sum\": 4077.932834625244, \"min\": 4077.932834625244}}, \"EndTime\": 1597163515.652508, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163511.574112}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:55 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.239703024 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:55 INFO 139712694728512] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=69, train loss <loss>=1.21695723534\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:55 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:56 INFO 139712694728512] Epoch[70] Batch[0] avg_epoch_loss=1.257274\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=1.25727427006\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:58 INFO 139712694728512] Epoch[70] Batch[5] avg_epoch_loss=1.239963\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=1.2399627169\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:31:58 INFO 139712694728512] Epoch[70] Batch [5]#011Speed: 182.16 samples/sec#011loss=1.239963\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] Epoch[70] Batch[10] avg_epoch_loss=1.174718\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=1.09642351866\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] Epoch[70] Batch [10]#011Speed: 182.61 samples/sec#011loss=1.096424\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4368.600845336914, \"sum\": 4368.600845336914, \"min\": 4368.600845336914}}, \"EndTime\": 1597163520.02172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163515.652602}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.700392687 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=70, train loss <loss>=1.17471762679\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] Epoch[71] Batch[0] avg_epoch_loss=1.310241\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=1.31024122238\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:02 INFO 139712694728512] Epoch[71] Batch[5] avg_epoch_loss=1.243970\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=1.243970414\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:02 INFO 139712694728512] Epoch[71] Batch [5]#011Speed: 177.20 samples/sec#011loss=1.243970\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:04 INFO 139712694728512] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4027.6529788970947, \"sum\": 4027.6529788970947, \"min\": 4027.6529788970947}}, \"EndTime\": 1597163524.049894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163520.021806}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:04 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.442348847 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:04 INFO 139712694728512] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=71, train loss <loss>=1.39203048944\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:04 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:04 INFO 139712694728512] Epoch[72] Batch[0] avg_epoch_loss=1.155490\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=1.15548968315\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:06 INFO 139712694728512] Epoch[72] Batch[5] avg_epoch_loss=1.228978\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=1.22897835573\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:06 INFO 139712694728512] Epoch[72] Batch [5]#011Speed: 180.42 samples/sec#011loss=1.228978\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:08 INFO 139712694728512] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3994.4489002227783, \"sum\": 3994.4489002227783, \"min\": 3994.4489002227783}}, \"EndTime\": 1597163528.044901, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163524.049962}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:08 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.961680139 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:08 INFO 139712694728512] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=72, train loss <loss>=1.23431161642\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:08 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:08 INFO 139712694728512] Epoch[73] Batch[0] avg_epoch_loss=1.155568\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=1.15556848049\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:10 INFO 139712694728512] Epoch[73] Batch[5] avg_epoch_loss=1.234401\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=1.23440092802\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:10 INFO 139712694728512] Epoch[73] Batch [5]#011Speed: 181.39 samples/sec#011loss=1.234401\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:12 INFO 139712694728512] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3998.508930206299, \"sum\": 3998.508930206299, \"min\": 3998.508930206299}}, \"EndTime\": 1597163532.044013, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163528.044981}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:12 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.052567661 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:12 INFO 139712694728512] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=73, train loss <loss>=1.25193761587\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:12 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:12 INFO 139712694728512] Epoch[74] Batch[0] avg_epoch_loss=1.487060\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=1.48705983162\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:14 INFO 139712694728512] Epoch[74] Batch[5] avg_epoch_loss=1.266552\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=1.26655157407\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:14 INFO 139712694728512] Epoch[74] Batch [5]#011Speed: 177.48 samples/sec#011loss=1.266552\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] Epoch[74] Batch[10] avg_epoch_loss=1.240918\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=1.21015734673\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] Epoch[74] Batch [10]#011Speed: 180.45 samples/sec#011loss=1.210157\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4408.720016479492, \"sum\": 4408.720016479492, \"min\": 4408.720016479492}}, \"EndTime\": 1597163536.453304, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163532.044105}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.111491341 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=74, train loss <loss>=1.24091783437\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:16 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:17 INFO 139712694728512] Epoch[75] Batch[0] avg_epoch_loss=1.213873\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=1.21387326717\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:19 INFO 139712694728512] Epoch[75] Batch[5] avg_epoch_loss=1.271052\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=1.27105204264\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:19 INFO 139712694728512] Epoch[75] Batch [5]#011Speed: 180.03 samples/sec#011loss=1.271052\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:20 INFO 139712694728512] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4053.7240505218506, \"sum\": 4053.7240505218506, \"min\": 4053.7240505218506}}, \"EndTime\": 1597163540.507564, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163536.453388}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:20 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.381757187 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:20 INFO 139712694728512] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=75, train loss <loss>=1.26735862494\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:20 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:21 INFO 139712694728512] Epoch[76] Batch[0] avg_epoch_loss=1.359260\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=1.35926008224\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:23 INFO 139712694728512] Epoch[76] Batch[5] avg_epoch_loss=1.312678\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=1.31267817815\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:23 INFO 139712694728512] Epoch[76] Batch [5]#011Speed: 176.76 samples/sec#011loss=1.312678\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:24 INFO 139712694728512] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4040.7369136810303, \"sum\": 4040.7369136810303, \"min\": 4040.7369136810303}}, \"EndTime\": 1597163544.548904, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163540.507636}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:24 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.453098532 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:24 INFO 139712694728512] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=76, train loss <loss>=1.27603024244\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:24 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:25 INFO 139712694728512] Epoch[77] Batch[0] avg_epoch_loss=1.359246\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=1.35924601555\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:27 INFO 139712694728512] Epoch[77] Batch[5] avg_epoch_loss=1.264028\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=1.26402805249\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:27 INFO 139712694728512] Epoch[77] Batch [5]#011Speed: 178.23 samples/sec#011loss=1.264028\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] Epoch[77] Batch[10] avg_epoch_loss=1.209424\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=1.14389965534\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] Epoch[77] Batch [10]#011Speed: 179.79 samples/sec#011loss=1.143900\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4396.0840702056885, \"sum\": 4396.0840702056885, \"min\": 4396.0840702056885}}, \"EndTime\": 1597163548.945602, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163544.548987}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.541697139 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=77, train loss <loss>=1.2094242356\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:28 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:29 INFO 139712694728512] Epoch[78] Batch[0] avg_epoch_loss=1.136605\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=1.1366045475\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:31 INFO 139712694728512] Epoch[78] Batch[5] avg_epoch_loss=1.236091\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=1.23609137535\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:31 INFO 139712694728512] Epoch[78] Batch [5]#011Speed: 180.54 samples/sec#011loss=1.236091\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] Epoch[78] Batch[10] avg_epoch_loss=1.242456\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=78, batch=10 train loss <loss>=1.25009304285\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] Epoch[78] Batch [10]#011Speed: 177.78 samples/sec#011loss=1.250093\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4403.11598777771, \"sum\": 4403.11598777771, \"min\": 4403.11598777771}}, \"EndTime\": 1597163553.349273, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163548.945676}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.205116623 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=78, train loss <loss>=1.24245576967\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:33 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:34 INFO 139712694728512] Epoch[79] Batch[0] avg_epoch_loss=1.101098\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:34 INFO 139712694728512] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=1.10109758377\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:35 INFO 139712694728512] Epoch[79] Batch[5] avg_epoch_loss=1.232627\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=1.2326267163\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:35 INFO 139712694728512] Epoch[79] Batch [5]#011Speed: 179.41 samples/sec#011loss=1.232627\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:37 INFO 139712694728512] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4051.0618686676025, \"sum\": 4051.0618686676025, \"min\": 4051.0618686676025}}, \"EndTime\": 1597163557.40092, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163553.349341}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:37 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.795478014 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:37 INFO 139712694728512] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=79, train loss <loss>=1.25073444843\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:37 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:38 INFO 139712694728512] Epoch[80] Batch[0] avg_epoch_loss=1.390690\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=1.39069020748\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:39 INFO 139712694728512] Epoch[80] Batch[5] avg_epoch_loss=1.264662\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=1.26466210683\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:39 INFO 139712694728512] Epoch[80] Batch [5]#011Speed: 181.03 samples/sec#011loss=1.264662\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] Epoch[80] Batch[10] avg_epoch_loss=1.223058\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=1.17313241959\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] Epoch[80] Batch [10]#011Speed: 178.92 samples/sec#011loss=1.173132\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4376.7900466918945, \"sum\": 4376.7900466918945, \"min\": 4376.7900466918945}}, \"EndTime\": 1597163561.778259, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163557.400991}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.136262613 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=80, train loss <loss>=1.22305770354\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:41 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:42 INFO 139712694728512] Epoch[81] Batch[0] avg_epoch_loss=1.134195\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=1.13419544697\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:44 INFO 139712694728512] Epoch[81] Batch[5] avg_epoch_loss=1.183442\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=1.18344173829\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:44 INFO 139712694728512] Epoch[81] Batch [5]#011Speed: 174.67 samples/sec#011loss=1.183442\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:45 INFO 139712694728512] processed a total of 611 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4087.818145751953, \"sum\": 4087.818145751953, \"min\": 4087.818145751953}}, \"EndTime\": 1597163565.866787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163561.778328}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:45 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.463554608 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:45 INFO 139712694728512] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=81, train loss <loss>=1.20853847265\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:45 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:46 INFO 139712694728512] Epoch[82] Batch[0] avg_epoch_loss=1.351316\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=1.35131621361\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:48 INFO 139712694728512] Epoch[82] Batch[5] avg_epoch_loss=1.218454\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=1.21845394373\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:48 INFO 139712694728512] Epoch[82] Batch [5]#011Speed: 180.07 samples/sec#011loss=1.218454\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] Epoch[82] Batch[10] avg_epoch_loss=1.220680\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=82, batch=10 train loss <loss>=1.22335059643\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] Epoch[82] Batch [10]#011Speed: 180.61 samples/sec#011loss=1.223351\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4390.958786010742, \"sum\": 4390.958786010742, \"min\": 4390.958786010742}}, \"EndTime\": 1597163570.258334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163565.86688}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.760074379 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=82, train loss <loss>=1.22067969496\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:50 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:51 INFO 139712694728512] Epoch[83] Batch[0] avg_epoch_loss=1.268205\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=1.26820492744\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:52 INFO 139712694728512] Epoch[83] Batch[5] avg_epoch_loss=1.224154\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=1.2241538167\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:52 INFO 139712694728512] Epoch[83] Batch [5]#011Speed: 176.49 samples/sec#011loss=1.224154\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:54 INFO 139712694728512] processed a total of 614 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4091.4859771728516, \"sum\": 4091.4859771728516, \"min\": 4091.4859771728516}}, \"EndTime\": 1597163574.350378, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163570.258421}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:54 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.062777489 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:54 INFO 139712694728512] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=83, train loss <loss>=1.15060704947\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:54 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:54 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_d04c181b-cb16-4ae6-b7cb-9a75f67466af-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 117.1579360961914, \"sum\": 117.1579360961914, \"min\": 117.1579360961914}}, \"EndTime\": 1597163574.468243, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163574.350473}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:55 INFO 139712694728512] Epoch[84] Batch[0] avg_epoch_loss=1.092854\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=1.09285378456\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:57 INFO 139712694728512] Epoch[84] Batch[5] avg_epoch_loss=1.112522\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=1.11252238353\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:57 INFO 139712694728512] Epoch[84] Batch [5]#011Speed: 180.29 samples/sec#011loss=1.112522\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:58 INFO 139712694728512] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4011.399030685425, \"sum\": 4011.399030685425, \"min\": 4011.399030685425}}, \"EndTime\": 1597163578.479801, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163574.468328}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:58 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.545792791 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:58 INFO 139712694728512] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=84, train loss <loss>=1.16565487385\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:58 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:59 INFO 139712694728512] Epoch[85] Batch[0] avg_epoch_loss=1.229515\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:32:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=1.22951507568\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:01 INFO 139712694728512] Epoch[85] Batch[5] avg_epoch_loss=1.227592\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=1.22759205103\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:01 INFO 139712694728512] Epoch[85] Batch [5]#011Speed: 181.29 samples/sec#011loss=1.227592\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:02 INFO 139712694728512] processed a total of 595 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4078.040838241577, \"sum\": 4078.040838241577, \"min\": 4078.040838241577}}, \"EndTime\": 1597163582.558377, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163578.479892}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:02 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=145.898600447 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:02 INFO 139712694728512] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=85, train loss <loss>=1.29972848892\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:02 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:03 INFO 139712694728512] Epoch[86] Batch[0] avg_epoch_loss=1.013317\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=1.01331686974\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:05 INFO 139712694728512] Epoch[86] Batch[5] avg_epoch_loss=1.231509\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=1.23150946697\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:05 INFO 139712694728512] Epoch[86] Batch [5]#011Speed: 181.64 samples/sec#011loss=1.231509\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] Epoch[86] Batch[10] avg_epoch_loss=1.208004\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=1.17979738712\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] Epoch[86] Batch [10]#011Speed: 180.81 samples/sec#011loss=1.179797\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4389.374017715454, \"sum\": 4389.374017715454, \"min\": 4389.374017715454}}, \"EndTime\": 1597163586.948348, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163582.55847}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.903319776 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=86, train loss <loss>=1.20800397613\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:06 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:07 INFO 139712694728512] Epoch[87] Batch[0] avg_epoch_loss=1.148065\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=1.14806520939\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:09 INFO 139712694728512] Epoch[87] Batch[5] avg_epoch_loss=1.176127\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=1.17612659931\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:09 INFO 139712694728512] Epoch[87] Batch [5]#011Speed: 181.12 samples/sec#011loss=1.176127\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4066.585063934326, \"sum\": 4066.585063934326, \"min\": 4066.585063934326}}, \"EndTime\": 1597163591.015451, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163586.948432}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.439818661 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=87, train loss <loss>=1.14233540893\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_2b3f6db4-a9c7-4d9f-b757-2e50998dd2df-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 131.80994987487793, \"sum\": 131.80994987487793, \"min\": 131.80994987487793}}, \"EndTime\": 1597163591.147902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163591.015567}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] Epoch[88] Batch[0] avg_epoch_loss=1.180184\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=1.1801841259\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:13 INFO 139712694728512] Epoch[88] Batch[5] avg_epoch_loss=1.195416\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=1.1954159538\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:13 INFO 139712694728512] Epoch[88] Batch [5]#011Speed: 174.90 samples/sec#011loss=1.195416\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] Epoch[88] Batch[10] avg_epoch_loss=1.142486\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=1.07897022367\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] Epoch[88] Batch [10]#011Speed: 182.75 samples/sec#011loss=1.078970\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4420.817852020264, \"sum\": 4420.817852020264, \"min\": 4420.817852020264}}, \"EndTime\": 1597163595.568882, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163591.147994}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.646283356 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=88, train loss <loss>=1.14248607646\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:15 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:16 INFO 139712694728512] Epoch[89] Batch[0] avg_epoch_loss=0.995017\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=0.995016872883\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:18 INFO 139712694728512] Epoch[89] Batch[5] avg_epoch_loss=1.123676\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=1.12367551525\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:18 INFO 139712694728512] Epoch[89] Batch [5]#011Speed: 180.51 samples/sec#011loss=1.123676\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:19 INFO 139712694728512] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4035.336971282959, \"sum\": 4035.336971282959, \"min\": 4035.336971282959}}, \"EndTime\": 1597163599.60474, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163595.568978}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:19 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.665215159 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:19 INFO 139712694728512] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=89, train loss <loss>=1.11707951427\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:19 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:19 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_693909a9-4adc-40b5-8831-a69dfea994d8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.42003059387207, \"sum\": 116.42003059387207, \"min\": 116.42003059387207}}, \"EndTime\": 1597163599.721736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163599.604808}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:20 INFO 139712694728512] Epoch[90] Batch[0] avg_epoch_loss=1.122112\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=1.12211215496\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:22 INFO 139712694728512] Epoch[90] Batch[5] avg_epoch_loss=1.211640\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=1.21164025863\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:22 INFO 139712694728512] Epoch[90] Batch [5]#011Speed: 179.06 samples/sec#011loss=1.211640\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] Epoch[90] Batch[10] avg_epoch_loss=1.126420\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=1.0241558671\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] Epoch[90] Batch [10]#011Speed: 180.32 samples/sec#011loss=1.024156\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] processed a total of 657 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4373.450994491577, \"sum\": 4373.450994491577, \"min\": 4373.450994491577}}, \"EndTime\": 1597163604.095331, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163599.721814}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.220907111 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=90, train loss <loss>=1.12642008066\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] Epoch[91] Batch[0] avg_epoch_loss=1.285178\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=1.2851780653\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:26 INFO 139712694728512] Epoch[91] Batch[5] avg_epoch_loss=1.165846\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=1.16584612926\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:26 INFO 139712694728512] Epoch[91] Batch [5]#011Speed: 182.49 samples/sec#011loss=1.165846\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] Epoch[91] Batch[10] avg_epoch_loss=1.204737\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=91, batch=10 train loss <loss>=1.25140562057\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] Epoch[91] Batch [10]#011Speed: 178.70 samples/sec#011loss=1.251406\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4368.237018585205, \"sum\": 4368.237018585205, \"min\": 4368.237018585205}}, \"EndTime\": 1597163608.464145, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163604.095403}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.640951645 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=91, train loss <loss>=1.20473680713\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:28 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:29 INFO 139712694728512] Epoch[92] Batch[0] avg_epoch_loss=1.249594\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=1.24959397316\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:31 INFO 139712694728512] Epoch[92] Batch[5] avg_epoch_loss=1.205987\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=1.20598733425\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:31 INFO 139712694728512] Epoch[92] Batch [5]#011Speed: 181.93 samples/sec#011loss=1.205987\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] Epoch[92] Batch[10] avg_epoch_loss=1.191465\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=1.17403857708\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] Epoch[92] Batch [10]#011Speed: 179.37 samples/sec#011loss=1.174039\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] processed a total of 666 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4354.3760776519775, \"sum\": 4354.3760776519775, \"min\": 4354.3760776519775}}, \"EndTime\": 1597163612.819079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163608.46423}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.944456718 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=92, train loss <loss>=1.1914651719\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:32 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:33 INFO 139712694728512] Epoch[93] Batch[0] avg_epoch_loss=1.079341\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=1.07934069633\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:35 INFO 139712694728512] Epoch[93] Batch[5] avg_epoch_loss=1.085704\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=1.08570382992\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:35 INFO 139712694728512] Epoch[93] Batch [5]#011Speed: 182.67 samples/sec#011loss=1.085704\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] Epoch[93] Batch[10] avg_epoch_loss=1.156463\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=93, batch=10 train loss <loss>=1.24137452841\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] Epoch[93] Batch [10]#011Speed: 181.19 samples/sec#011loss=1.241375\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4336.277961730957, \"sum\": 4336.277961730957, \"min\": 4336.277961730957}}, \"EndTime\": 1597163617.155964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163612.819182}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.889239806 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=93, train loss <loss>=1.15646323833\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] Epoch[94] Batch[0] avg_epoch_loss=1.158257\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=1.15825653076\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:39 INFO 139712694728512] Epoch[94] Batch[5] avg_epoch_loss=1.119580\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=1.11958018939\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:39 INFO 139712694728512] Epoch[94] Batch [5]#011Speed: 182.21 samples/sec#011loss=1.119580\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:41 INFO 139712694728512] processed a total of 629 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3998.584985733032, \"sum\": 3998.584985733032, \"min\": 3998.584985733032}}, \"EndTime\": 1597163621.155126, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163617.156056}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:41 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.301089146 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:41 INFO 139712694728512] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=94, train loss <loss>=1.14235021472\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:41 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:41 INFO 139712694728512] Epoch[95] Batch[0] avg_epoch_loss=1.172037\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=1.17203700542\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:43 INFO 139712694728512] Epoch[95] Batch[5] avg_epoch_loss=1.165509\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=1.16550890605\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:43 INFO 139712694728512] Epoch[95] Batch [5]#011Speed: 180.42 samples/sec#011loss=1.165509\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] Epoch[95] Batch[10] avg_epoch_loss=1.123449\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=1.07297800779\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] Epoch[95] Batch [10]#011Speed: 179.76 samples/sec#011loss=1.072978\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4363.4819984436035, \"sum\": 4363.4819984436035, \"min\": 4363.4819984436035}}, \"EndTime\": 1597163625.519306, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163621.155201}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.126096906 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=95, train loss <loss>=1.12344940684\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:45 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:46 INFO 139712694728512] Epoch[96] Batch[0] avg_epoch_loss=1.409104\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=1.4091039896\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:48 INFO 139712694728512] Epoch[96] Batch[5] avg_epoch_loss=1.234824\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=1.23482350508\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:48 INFO 139712694728512] Epoch[96] Batch [5]#011Speed: 178.63 samples/sec#011loss=1.234824\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] Epoch[96] Batch[10] avg_epoch_loss=1.347625\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=1.48298683167\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] Epoch[96] Batch [10]#011Speed: 181.45 samples/sec#011loss=1.482987\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4361.724853515625, \"sum\": 4361.724853515625, \"min\": 4361.724853515625}}, \"EndTime\": 1597163629.881618, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163625.519387}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.560743209 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=96, train loss <loss>=1.34762501717\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:49 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:50 INFO 139712694728512] Epoch[97] Batch[0] avg_epoch_loss=1.076655\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=1.07665514946\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:52 INFO 139712694728512] Epoch[97] Batch[5] avg_epoch_loss=1.103498\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=1.103497684\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:52 INFO 139712694728512] Epoch[97] Batch [5]#011Speed: 178.85 samples/sec#011loss=1.103498\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] Epoch[97] Batch[10] avg_epoch_loss=1.151219\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=97, batch=10 train loss <loss>=1.20848546028\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] Epoch[97] Batch [10]#011Speed: 182.51 samples/sec#011loss=1.208485\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4356.019973754883, \"sum\": 4356.019973754883, \"min\": 4356.019973754883}}, \"EndTime\": 1597163634.238178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163629.881704}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.362406316 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=97, train loss <loss>=1.15121940049\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:54 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:55 INFO 139712694728512] Epoch[98] Batch[0] avg_epoch_loss=1.175889\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=1.17588925362\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:56 INFO 139712694728512] Epoch[98] Batch[5] avg_epoch_loss=1.196303\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=1.19630308946\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:56 INFO 139712694728512] Epoch[98] Batch [5]#011Speed: 179.87 samples/sec#011loss=1.196303\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] Epoch[98] Batch[10] avg_epoch_loss=1.250927\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=98, batch=10 train loss <loss>=1.3164760828\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] Epoch[98] Batch [10]#011Speed: 179.29 samples/sec#011loss=1.316476\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4391.464948654175, \"sum\": 4391.464948654175, \"min\": 4391.464948654175}}, \"EndTime\": 1597163638.63015, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163634.238263}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.466093701 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=98, train loss <loss>=1.25092717734\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:58 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:59 INFO 139712694728512] Epoch[99] Batch[0] avg_epoch_loss=1.072037\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:33:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=1.07203662395\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:01 INFO 139712694728512] Epoch[99] Batch[5] avg_epoch_loss=1.130040\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=1.13003991048\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:01 INFO 139712694728512] Epoch[99] Batch [5]#011Speed: 182.40 samples/sec#011loss=1.130040\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] Epoch[99] Batch[10] avg_epoch_loss=1.120126\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=99, batch=10 train loss <loss>=1.10822999477\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] Epoch[99] Batch [10]#011Speed: 178.60 samples/sec#011loss=1.108230\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4365.533828735352, \"sum\": 4365.533828735352, \"min\": 4365.533828735352}}, \"EndTime\": 1597163642.996224, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163638.630223}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.448359054 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=99, train loss <loss>=1.12012631243\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:02 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:03 INFO 139712694728512] Epoch[100] Batch[0] avg_epoch_loss=1.007982\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=1.00798153877\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:05 INFO 139712694728512] Epoch[100] Batch[5] avg_epoch_loss=1.165073\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=1.16507273912\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:05 INFO 139712694728512] Epoch[100] Batch [5]#011Speed: 181.47 samples/sec#011loss=1.165073\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:07 INFO 139712694728512] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4033.1990718841553, \"sum\": 4033.1990718841553, \"min\": 4033.1990718841553}}, \"EndTime\": 1597163647.029953, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163642.996311}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:07 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.008239213 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:07 INFO 139712694728512] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=100, train loss <loss>=1.18254796267\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:07 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:07 INFO 139712694728512] Epoch[101] Batch[0] avg_epoch_loss=1.263160\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=1.26315951347\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:09 INFO 139712694728512] Epoch[101] Batch[5] avg_epoch_loss=1.134065\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=1.13406523069\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:09 INFO 139712694728512] Epoch[101] Batch [5]#011Speed: 179.68 samples/sec#011loss=1.134065\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] Epoch[101] Batch[10] avg_epoch_loss=1.083868\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=101, batch=10 train loss <loss>=1.02363029718\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] Epoch[101] Batch [10]#011Speed: 176.60 samples/sec#011loss=1.023630\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4457.751989364624, \"sum\": 4457.751989364624, \"min\": 4457.751989364624}}, \"EndTime\": 1597163651.488275, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163647.030047}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.744468606 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=101, train loss <loss>=1.08386753364\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:11 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_0fd9d575-0ab0-41f3-852e-6bfeb012c7b5-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.99897384643555, \"sum\": 125.99897384643555, \"min\": 125.99897384643555}}, \"EndTime\": 1597163651.614889, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163651.488361}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:12 INFO 139712694728512] Epoch[102] Batch[0] avg_epoch_loss=1.281875\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=1.28187513351\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:14 INFO 139712694728512] Epoch[102] Batch[5] avg_epoch_loss=1.169475\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=1.16947548588\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:14 INFO 139712694728512] Epoch[102] Batch [5]#011Speed: 177.44 samples/sec#011loss=1.169475\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:15 INFO 139712694728512] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4052.2191524505615, \"sum\": 4052.2191524505615, \"min\": 4052.2191524505615}}, \"EndTime\": 1597163655.667269, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163651.614981}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:15 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.542671451 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:15 INFO 139712694728512] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=102, train loss <loss>=1.20388490558\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:15 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:16 INFO 139712694728512] Epoch[103] Batch[0] avg_epoch_loss=1.149378\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=1.14937829971\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:18 INFO 139712694728512] Epoch[103] Batch[5] avg_epoch_loss=1.174457\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=1.17445685466\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:18 INFO 139712694728512] Epoch[103] Batch [5]#011Speed: 177.44 samples/sec#011loss=1.174457\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] Epoch[103] Batch[10] avg_epoch_loss=1.116768\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=1.04754190445\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] Epoch[103] Batch [10]#011Speed: 180.24 samples/sec#011loss=1.047542\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4443.861961364746, \"sum\": 4443.861961364746, \"min\": 4443.861961364746}}, \"EndTime\": 1597163660.111717, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163655.667364}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.165182108 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=103, train loss <loss>=1.11676824093\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] Epoch[104] Batch[0] avg_epoch_loss=1.130630\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=1.13063013554\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:22 INFO 139712694728512] Epoch[104] Batch[5] avg_epoch_loss=1.204775\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=1.20477495591\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:22 INFO 139712694728512] Epoch[104] Batch [5]#011Speed: 178.37 samples/sec#011loss=1.204775\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] Epoch[104] Batch[10] avg_epoch_loss=1.258017\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=104, batch=10 train loss <loss>=1.32190759182\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] Epoch[104] Batch [10]#011Speed: 178.35 samples/sec#011loss=1.321908\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4432.780027389526, \"sum\": 4432.780027389526, \"min\": 4432.780027389526}}, \"EndTime\": 1597163664.545022, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163660.111804}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.593562616 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=104, train loss <loss>=1.25801706314\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:24 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:25 INFO 139712694728512] Epoch[105] Batch[0] avg_epoch_loss=1.174356\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=1.17435574532\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:27 INFO 139712694728512] Epoch[105] Batch[5] avg_epoch_loss=1.180031\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=1.18003121018\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:27 INFO 139712694728512] Epoch[105] Batch [5]#011Speed: 183.99 samples/sec#011loss=1.180031\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:28 INFO 139712694728512] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3988.968849182129, \"sum\": 3988.968849182129, \"min\": 3988.968849182129}}, \"EndTime\": 1597163668.534537, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163664.54511}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:28 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.161808588 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:28 INFO 139712694728512] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=105, train loss <loss>=1.20906805396\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:28 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:29 INFO 139712694728512] Epoch[106] Batch[0] avg_epoch_loss=1.114180\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=1.11417973042\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:31 INFO 139712694728512] Epoch[106] Batch[5] avg_epoch_loss=1.191722\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=1.19172155857\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:31 INFO 139712694728512] Epoch[106] Batch [5]#011Speed: 181.54 samples/sec#011loss=1.191722\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:32 INFO 139712694728512] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4004.8599243164062, \"sum\": 4004.8599243164062, \"min\": 4004.8599243164062}}, \"EndTime\": 1597163672.53997, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163668.534631}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:32 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.05765309 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:32 INFO 139712694728512] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=106, train loss <loss>=1.10258660913\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:32 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:33 INFO 139712694728512] Epoch[107] Batch[0] avg_epoch_loss=1.051586\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=1.05158603191\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:35 INFO 139712694728512] Epoch[107] Batch[5] avg_epoch_loss=1.141107\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=1.1411070923\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:35 INFO 139712694728512] Epoch[107] Batch [5]#011Speed: 180.96 samples/sec#011loss=1.141107\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] Epoch[107] Batch[10] avg_epoch_loss=1.027689\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=0.891587254405\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] Epoch[107] Batch [10]#011Speed: 181.14 samples/sec#011loss=0.891587\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4382.697105407715, \"sum\": 4382.697105407715, \"min\": 4382.697105407715}}, \"EndTime\": 1597163676.923236, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163672.540064}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.252904619 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=107, train loss <loss>=1.02768898417\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:36 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:37 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_857ca2e6-8363-45f8-9eee-960628bbfd2b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 127.15911865234375, \"sum\": 127.15911865234375, \"min\": 127.15911865234375}}, \"EndTime\": 1597163677.051051, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163676.923321}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:37 INFO 139712694728512] Epoch[108] Batch[0] avg_epoch_loss=1.138968\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=1.13896799088\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:39 INFO 139712694728512] Epoch[108] Batch[5] avg_epoch_loss=1.146818\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=1.14681829015\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:39 INFO 139712694728512] Epoch[108] Batch [5]#011Speed: 181.12 samples/sec#011loss=1.146818\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] Epoch[108] Batch[10] avg_epoch_loss=1.107442\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=1.06019032001\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] Epoch[108] Batch [10]#011Speed: 180.56 samples/sec#011loss=1.060190\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4403.03897857666, \"sum\": 4403.03897857666, \"min\": 4403.03897857666}}, \"EndTime\": 1597163681.454231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163677.051127}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.48559944 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=108, train loss <loss>=1.10744194009\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:41 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:42 INFO 139712694728512] Epoch[109] Batch[0] avg_epoch_loss=0.898447\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=109, batch=0 train loss <loss>=0.898446559906\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:44 INFO 139712694728512] Epoch[109] Batch[5] avg_epoch_loss=1.178315\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=109, batch=5 train loss <loss>=1.17831544081\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:44 INFO 139712694728512] Epoch[109] Batch [5]#011Speed: 177.65 samples/sec#011loss=1.178315\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:45 INFO 139712694728512] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4086.5399837493896, \"sum\": 4086.5399837493896, \"min\": 4086.5399837493896}}, \"EndTime\": 1597163685.541274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163681.454316}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:45 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.467918358 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:45 INFO 139712694728512] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=109, train loss <loss>=1.15555121303\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:45 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:46 INFO 139712694728512] Epoch[110] Batch[0] avg_epoch_loss=1.044508\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=110, batch=0 train loss <loss>=1.04450798035\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:48 INFO 139712694728512] Epoch[110] Batch[5] avg_epoch_loss=1.169751\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=110, batch=5 train loss <loss>=1.16975140572\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:48 INFO 139712694728512] Epoch[110] Batch [5]#011Speed: 179.05 samples/sec#011loss=1.169751\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] Epoch[110] Batch[10] avg_epoch_loss=1.190166\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=110, batch=10 train loss <loss>=1.2146625042\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] Epoch[110] Batch [10]#011Speed: 180.23 samples/sec#011loss=1.214663\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] processed a total of 692 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4426.167964935303, \"sum\": 4426.167964935303, \"min\": 4426.167964935303}}, \"EndTime\": 1597163689.968, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163685.541368}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.338602868 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=110, train loss <loss>=1.19016554139\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:49 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:50 INFO 139712694728512] Epoch[111] Batch[0] avg_epoch_loss=1.078359\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=111, batch=0 train loss <loss>=1.07835936546\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:52 INFO 139712694728512] Epoch[111] Batch[5] avg_epoch_loss=1.176956\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=111, batch=5 train loss <loss>=1.17695564032\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:52 INFO 139712694728512] Epoch[111] Batch [5]#011Speed: 180.27 samples/sec#011loss=1.176956\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] Epoch[111] Batch[10] avg_epoch_loss=1.162347\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=111, batch=10 train loss <loss>=1.14481618404\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] Epoch[111] Batch [10]#011Speed: 174.14 samples/sec#011loss=1.144816\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4469.027996063232, \"sum\": 4469.027996063232, \"min\": 4469.027996063232}}, \"EndTime\": 1597163694.437551, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163689.968084}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=144.546338049 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=111, train loss <loss>=1.16234679656\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:54 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:55 INFO 139712694728512] Epoch[112] Batch[0] avg_epoch_loss=1.202351\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=112, batch=0 train loss <loss>=1.20235061646\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:57 INFO 139712694728512] Epoch[112] Batch[5] avg_epoch_loss=1.203192\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=112, batch=5 train loss <loss>=1.20319235325\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:57 INFO 139712694728512] Epoch[112] Batch [5]#011Speed: 180.24 samples/sec#011loss=1.203192\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:58 INFO 139712694728512] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4005.889892578125, \"sum\": 4005.889892578125, \"min\": 4005.889892578125}}, \"EndTime\": 1597163698.444049, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163694.437635}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:58 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.019666275 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:58 INFO 139712694728512] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=112, train loss <loss>=1.13695025444\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:58 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:59 INFO 139712694728512] Epoch[113] Batch[0] avg_epoch_loss=1.120934\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:34:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=113, batch=0 train loss <loss>=1.12093400955\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:01 INFO 139712694728512] Epoch[113] Batch[5] avg_epoch_loss=1.153560\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=113, batch=5 train loss <loss>=1.15356032054\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:01 INFO 139712694728512] Epoch[113] Batch [5]#011Speed: 181.73 samples/sec#011loss=1.153560\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] Epoch[113] Batch[10] avg_epoch_loss=1.139963\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=113, batch=10 train loss <loss>=1.12364683151\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] Epoch[113] Batch [10]#011Speed: 172.67 samples/sec#011loss=1.123647\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4450.026988983154, \"sum\": 4450.026988983154, \"min\": 4450.026988983154}}, \"EndTime\": 1597163702.89464, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163698.444141}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.028303197 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=113, train loss <loss>=1.13996328007\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:02 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:03 INFO 139712694728512] Epoch[114] Batch[0] avg_epoch_loss=0.951392\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=114, batch=0 train loss <loss>=0.951391935349\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:05 INFO 139712694728512] Epoch[114] Batch[5] avg_epoch_loss=1.089583\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=114, batch=5 train loss <loss>=1.08958270152\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:05 INFO 139712694728512] Epoch[114] Batch [5]#011Speed: 180.32 samples/sec#011loss=1.089583\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] Epoch[114] Batch[10] avg_epoch_loss=1.007781\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=114, batch=10 train loss <loss>=0.90961894393\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] Epoch[114] Batch [10]#011Speed: 179.68 samples/sec#011loss=0.909619\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4383.111000061035, \"sum\": 4383.111000061035, \"min\": 4383.111000061035}}, \"EndTime\": 1597163707.278321, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163702.894729}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.467132969 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=114, train loss <loss>=1.00778099353\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:07 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_441ffc33-3f5c-4ddb-aab2-173e5887b12b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 118.59488487243652, \"sum\": 118.59488487243652, \"min\": 118.59488487243652}}, \"EndTime\": 1597163707.397518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163707.278405}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:08 INFO 139712694728512] Epoch[115] Batch[0] avg_epoch_loss=1.278303\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=115, batch=0 train loss <loss>=1.27830338478\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:09 INFO 139712694728512] Epoch[115] Batch[5] avg_epoch_loss=1.256333\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=115, batch=5 train loss <loss>=1.25633335114\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:09 INFO 139712694728512] Epoch[115] Batch [5]#011Speed: 180.31 samples/sec#011loss=1.256333\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:11 INFO 139712694728512] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4046.2138652801514, \"sum\": 4046.2138652801514, \"min\": 4046.2138652801514}}, \"EndTime\": 1597163711.443894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163707.397605}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:11 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.023228781 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:11 INFO 139712694728512] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=115, train loss <loss>=1.2149443984\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:11 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:12 INFO 139712694728512] Epoch[116] Batch[0] avg_epoch_loss=1.288476\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=116, batch=0 train loss <loss>=1.28847587109\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:14 INFO 139712694728512] Epoch[116] Batch[5] avg_epoch_loss=1.122636\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=116, batch=5 train loss <loss>=1.12263552348\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:14 INFO 139712694728512] Epoch[116] Batch [5]#011Speed: 179.38 samples/sec#011loss=1.122636\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] Epoch[116] Batch[10] avg_epoch_loss=1.048220\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=116, batch=10 train loss <loss>=0.958920532465\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] Epoch[116] Batch [10]#011Speed: 166.76 samples/sec#011loss=0.958921\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4549.870014190674, \"sum\": 4549.870014190674, \"min\": 4549.870014190674}}, \"EndTime\": 1597163715.994341, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163711.443988}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=141.9781425 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=116, train loss <loss>=1.04821961847\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:15 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:16 INFO 139712694728512] Epoch[117] Batch[0] avg_epoch_loss=1.264751\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=117, batch=0 train loss <loss>=1.26475131512\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:18 INFO 139712694728512] Epoch[117] Batch[5] avg_epoch_loss=1.078014\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=117, batch=5 train loss <loss>=1.07801406582\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:18 INFO 139712694728512] Epoch[117] Batch [5]#011Speed: 170.58 samples/sec#011loss=1.078014\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:20 INFO 139712694728512] processed a total of 609 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4145.12300491333, \"sum\": 4145.12300491333, \"min\": 4145.12300491333}}, \"EndTime\": 1597163720.139991, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163715.994428}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:20 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.914786034 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:20 INFO 139712694728512] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=117, train loss <loss>=1.11149389148\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:20 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:20 INFO 139712694728512] Epoch[118] Batch[0] avg_epoch_loss=1.317602\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=118, batch=0 train loss <loss>=1.31760179996\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:22 INFO 139712694728512] Epoch[118] Batch[5] avg_epoch_loss=1.129252\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=118, batch=5 train loss <loss>=1.12925249338\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:22 INFO 139712694728512] Epoch[118] Batch [5]#011Speed: 181.32 samples/sec#011loss=1.129252\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] Epoch[118] Batch[10] avg_epoch_loss=1.132226\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=118, batch=10 train loss <loss>=1.13579411507\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] Epoch[118] Batch [10]#011Speed: 177.39 samples/sec#011loss=1.135794\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4421.519994735718, \"sum\": 4421.519994735718, \"min\": 4421.519994735718}}, \"EndTime\": 1597163724.562068, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163720.140087}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.015180329 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] #progress_metric: host=algo-1, completed 29 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=118, train loss <loss>=1.13222595778\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:24 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:25 INFO 139712694728512] Epoch[119] Batch[0] avg_epoch_loss=1.126696\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=119, batch=0 train loss <loss>=1.12669599056\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:27 INFO 139712694728512] Epoch[119] Batch[5] avg_epoch_loss=1.145595\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=119, batch=5 train loss <loss>=1.14559529225\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:27 INFO 139712694728512] Epoch[119] Batch [5]#011Speed: 181.65 samples/sec#011loss=1.145595\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:28 INFO 139712694728512] processed a total of 616 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4041.677951812744, \"sum\": 4041.677951812744, \"min\": 4041.677951812744}}, \"EndTime\": 1597163728.604271, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163724.562154}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:28 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.407081712 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:28 INFO 139712694728512] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=119, train loss <loss>=1.13132395744\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:28 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:29 INFO 139712694728512] Epoch[120] Batch[0] avg_epoch_loss=1.211985\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=120, batch=0 train loss <loss>=1.21198475361\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:31 INFO 139712694728512] Epoch[120] Batch[5] avg_epoch_loss=1.124367\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=120, batch=5 train loss <loss>=1.12436701854\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:31 INFO 139712694728512] Epoch[120] Batch [5]#011Speed: 180.22 samples/sec#011loss=1.124367\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] Epoch[120] Batch[10] avg_epoch_loss=1.083652\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=120, batch=10 train loss <loss>=1.03479454517\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] Epoch[120] Batch [10]#011Speed: 178.30 samples/sec#011loss=1.034795\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4420.289993286133, \"sum\": 4420.289993286133, \"min\": 4420.289993286133}}, \"EndTime\": 1597163733.025126, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163728.60436}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=145.009043093 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=120, train loss <loss>=1.08365225792\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] Epoch[121] Batch[0] avg_epoch_loss=1.362716\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=121, batch=0 train loss <loss>=1.36271631718\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:35 INFO 139712694728512] Epoch[121] Batch[5] avg_epoch_loss=1.160479\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=121, batch=5 train loss <loss>=1.16047944625\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:35 INFO 139712694728512] Epoch[121] Batch [5]#011Speed: 181.51 samples/sec#011loss=1.160479\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] Epoch[121] Batch[10] avg_epoch_loss=1.072291\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=121, batch=10 train loss <loss>=0.966464483738\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] Epoch[121] Batch [10]#011Speed: 181.06 samples/sec#011loss=0.966464\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4397.892951965332, \"sum\": 4397.892951965332, \"min\": 4397.892951965332}}, \"EndTime\": 1597163737.423592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163733.025211}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.248770139 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=121, train loss <loss>=1.07229082693\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:37 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:38 INFO 139712694728512] Epoch[122] Batch[0] avg_epoch_loss=1.183027\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=122, batch=0 train loss <loss>=1.18302679062\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:40 INFO 139712694728512] Epoch[122] Batch[5] avg_epoch_loss=1.089324\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=122, batch=5 train loss <loss>=1.08932407697\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:40 INFO 139712694728512] Epoch[122] Batch [5]#011Speed: 179.32 samples/sec#011loss=1.089324\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] Epoch[122] Batch[10] avg_epoch_loss=1.026599\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=122, batch=10 train loss <loss>=0.951329088211\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] Epoch[122] Batch [10]#011Speed: 180.36 samples/sec#011loss=0.951329\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4444.252014160156, \"sum\": 4444.252014160156, \"min\": 4444.252014160156}}, \"EndTime\": 1597163741.868346, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163737.423676}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.177425647 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=122, train loss <loss>=1.02659908208\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:41 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:42 INFO 139712694728512] Epoch[123] Batch[0] avg_epoch_loss=0.960872\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=123, batch=0 train loss <loss>=0.960872292519\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:44 INFO 139712694728512] Epoch[123] Batch[5] avg_epoch_loss=1.077084\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=123, batch=5 train loss <loss>=1.07708416382\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:44 INFO 139712694728512] Epoch[123] Batch [5]#011Speed: 176.11 samples/sec#011loss=1.077084\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] Epoch[123] Batch[10] avg_epoch_loss=1.095277\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=123, batch=10 train loss <loss>=1.11710829735\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] Epoch[123] Batch [10]#011Speed: 181.16 samples/sec#011loss=1.117108\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4806.196928024292, \"sum\": 4806.196928024292, \"min\": 4806.196928024292}}, \"EndTime\": 1597163746.675075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163741.868429}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.513888376 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=123, train loss <loss>=0.994578884915\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:46 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_4931eecc-bc42-4d28-9af4-32bfd4201eea-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 116.45793914794922, \"sum\": 116.45793914794922, \"min\": 116.45793914794922}}, \"EndTime\": 1597163746.792231, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163746.675168}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:47 INFO 139712694728512] Epoch[124] Batch[0] avg_epoch_loss=1.017935\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:47 INFO 139712694728512] #quality_metric: host=algo-1, epoch=124, batch=0 train loss <loss>=1.01793527603\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:49 INFO 139712694728512] Epoch[124] Batch[5] avg_epoch_loss=1.103101\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=124, batch=5 train loss <loss>=1.10310101509\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:49 INFO 139712694728512] Epoch[124] Batch [5]#011Speed: 179.10 samples/sec#011loss=1.103101\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] Epoch[124] Batch[10] avg_epoch_loss=1.087969\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=124, batch=10 train loss <loss>=1.06981061697\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] Epoch[124] Batch [10]#011Speed: 179.82 samples/sec#011loss=1.069811\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4389.424085617065, \"sum\": 4389.424085617065, \"min\": 4389.424085617065}}, \"EndTime\": 1597163751.181798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163746.792318}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.357474781 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=124, train loss <loss>=1.08796901595\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:51 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:52 INFO 139712694728512] Epoch[125] Batch[0] avg_epoch_loss=0.831970\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=125, batch=0 train loss <loss>=0.831969976425\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:53 INFO 139712694728512] Epoch[125] Batch[5] avg_epoch_loss=1.062709\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:53 INFO 139712694728512] #quality_metric: host=algo-1, epoch=125, batch=5 train loss <loss>=1.06270873547\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:53 INFO 139712694728512] Epoch[125] Batch [5]#011Speed: 179.66 samples/sec#011loss=1.062709\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] Epoch[125] Batch[10] avg_epoch_loss=1.127150\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=125, batch=10 train loss <loss>=1.20447998047\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] Epoch[125] Batch [10]#011Speed: 180.04 samples/sec#011loss=1.204480\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4387.628078460693, \"sum\": 4387.628078460693, \"min\": 4387.628078460693}}, \"EndTime\": 1597163755.570002, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163751.181877}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.609308799 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=125, train loss <loss>=1.12715021047\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:55 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:56 INFO 139712694728512] Epoch[126] Batch[0] avg_epoch_loss=0.968726\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=126, batch=0 train loss <loss>=0.968726098537\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:58 INFO 139712694728512] Epoch[126] Batch[5] avg_epoch_loss=1.088490\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=126, batch=5 train loss <loss>=1.0884898901\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:58 INFO 139712694728512] Epoch[126] Batch [5]#011Speed: 180.25 samples/sec#011loss=1.088490\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:59 INFO 139712694728512] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4007.2238445281982, \"sum\": 4007.2238445281982, \"min\": 4007.2238445281982}}, \"EndTime\": 1597163759.577799, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163755.570088}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:59 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.214904874 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:59 INFO 139712694728512] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=126, train loss <loss>=1.10701384544\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:35:59 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:00 INFO 139712694728512] Epoch[127] Batch[0] avg_epoch_loss=1.183292\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=127, batch=0 train loss <loss>=1.18329203129\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:02 INFO 139712694728512] Epoch[127] Batch[5] avg_epoch_loss=1.075896\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=127, batch=5 train loss <loss>=1.0758960247\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:02 INFO 139712694728512] Epoch[127] Batch [5]#011Speed: 179.51 samples/sec#011loss=1.075896\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] Epoch[127] Batch[10] avg_epoch_loss=1.135884\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=127, batch=10 train loss <loss>=1.20786921978\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] Epoch[127] Batch [10]#011Speed: 179.36 samples/sec#011loss=1.207869\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] processed a total of 660 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4388.3020877838135, \"sum\": 4388.3020877838135, \"min\": 4388.3020877838135}}, \"EndTime\": 1597163763.966688, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163759.577881}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.395949746 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=127, train loss <loss>=1.13588384065\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:03 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:04 INFO 139712694728512] Epoch[128] Batch[0] avg_epoch_loss=1.198479\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=128, batch=0 train loss <loss>=1.19847929478\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:06 INFO 139712694728512] Epoch[128] Batch[5] avg_epoch_loss=1.122977\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=128, batch=5 train loss <loss>=1.12297654152\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:06 INFO 139712694728512] Epoch[128] Batch [5]#011Speed: 180.98 samples/sec#011loss=1.122977\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:07 INFO 139712694728512] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4006.784200668335, \"sum\": 4006.784200668335, \"min\": 4006.784200668335}}, \"EndTime\": 1597163767.974021, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163763.966759}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:07 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=159.72359805 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:07 INFO 139712694728512] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=128, train loss <loss>=1.10437335372\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:07 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:08 INFO 139712694728512] Epoch[129] Batch[0] avg_epoch_loss=0.775065\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=129, batch=0 train loss <loss>=0.775065362453\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:10 INFO 139712694728512] Epoch[129] Batch[5] avg_epoch_loss=1.079861\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=129, batch=5 train loss <loss>=1.07986130317\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:10 INFO 139712694728512] Epoch[129] Batch [5]#011Speed: 180.91 samples/sec#011loss=1.079861\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] Epoch[129] Batch[10] avg_epoch_loss=1.100373\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=129, batch=10 train loss <loss>=1.12498614788\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] Epoch[129] Batch [10]#011Speed: 177.61 samples/sec#011loss=1.124986\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] processed a total of 670 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4400.467872619629, \"sum\": 4400.467872619629, \"min\": 4400.467872619629}}, \"EndTime\": 1597163772.37514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163767.974116}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.252272352 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=129, train loss <loss>=1.10037259622\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:12 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:13 INFO 139712694728512] Epoch[130] Batch[0] avg_epoch_loss=0.989237\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=130, batch=0 train loss <loss>=0.989237308502\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:15 INFO 139712694728512] Epoch[130] Batch[5] avg_epoch_loss=1.056514\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=130, batch=5 train loss <loss>=1.05651411414\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:15 INFO 139712694728512] Epoch[130] Batch [5]#011Speed: 179.28 samples/sec#011loss=1.056514\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] Epoch[130] Batch[10] avg_epoch_loss=1.097984\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=130, batch=10 train loss <loss>=1.14774676561\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] Epoch[130] Batch [10]#011Speed: 180.74 samples/sec#011loss=1.147747\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4436.29789352417, \"sum\": 4436.29789352417, \"min\": 4436.29789352417}}, \"EndTime\": 1597163776.812017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163772.375225}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.514359957 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=130, train loss <loss>=1.09798350117\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:16 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:17 INFO 139712694728512] Epoch[131] Batch[0] avg_epoch_loss=1.250832\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=131, batch=0 train loss <loss>=1.25083243847\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:19 INFO 139712694728512] Epoch[131] Batch[5] avg_epoch_loss=1.100389\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=131, batch=5 train loss <loss>=1.10038852692\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:19 INFO 139712694728512] Epoch[131] Batch [5]#011Speed: 180.30 samples/sec#011loss=1.100389\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] Epoch[131] Batch[10] avg_epoch_loss=1.119603\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=131, batch=10 train loss <loss>=1.14266039133\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] Epoch[131] Batch [10]#011Speed: 179.99 samples/sec#011loss=1.142660\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4398.138999938965, \"sum\": 4398.138999938965, \"min\": 4398.138999938965}}, \"EndTime\": 1597163781.210685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163776.812106}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.013009789 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=131, train loss <loss>=1.11960301074\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:21 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:22 INFO 139712694728512] Epoch[132] Batch[0] avg_epoch_loss=1.073118\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=132, batch=0 train loss <loss>=1.07311820984\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:23 INFO 139712694728512] Epoch[132] Batch[5] avg_epoch_loss=1.133659\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=132, batch=5 train loss <loss>=1.13365872701\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:23 INFO 139712694728512] Epoch[132] Batch [5]#011Speed: 182.67 samples/sec#011loss=1.133659\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:25 INFO 139712694728512] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4003.7310123443604, \"sum\": 4003.7310123443604, \"min\": 4003.7310123443604}}, \"EndTime\": 1597163785.214937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163781.210772}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:25 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.850338802 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:25 INFO 139712694728512] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=132, train loss <loss>=1.12240304947\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:25 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:26 INFO 139712694728512] Epoch[133] Batch[0] avg_epoch_loss=1.084483\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=133, batch=0 train loss <loss>=1.08448255062\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:27 INFO 139712694728512] Epoch[133] Batch[5] avg_epoch_loss=1.082496\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=133, batch=5 train loss <loss>=1.08249648412\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:27 INFO 139712694728512] Epoch[133] Batch [5]#011Speed: 183.42 samples/sec#011loss=1.082496\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:29 INFO 139712694728512] processed a total of 593 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3977.8921604156494, \"sum\": 3977.8921604156494, \"min\": 3977.8921604156494}}, \"EndTime\": 1597163789.193491, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163785.215032}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:29 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.068868637 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:29 INFO 139712694728512] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=133, train loss <loss>=1.10553750992\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:29 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:30 INFO 139712694728512] Epoch[134] Batch[0] avg_epoch_loss=0.975010\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:30 INFO 139712694728512] #quality_metric: host=algo-1, epoch=134, batch=0 train loss <loss>=0.975010037422\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:31 INFO 139712694728512] Epoch[134] Batch[5] avg_epoch_loss=1.114646\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=134, batch=5 train loss <loss>=1.11464581887\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:31 INFO 139712694728512] Epoch[134] Batch [5]#011Speed: 181.84 samples/sec#011loss=1.114646\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:33 INFO 139712694728512] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4000.822067260742, \"sum\": 4000.822067260742, \"min\": 4000.822067260742}}, \"EndTime\": 1597163793.194927, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163789.193584}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:33 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=159.961766798 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:33 INFO 139712694728512] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=134, train loss <loss>=1.1143671155\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:33 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:34 INFO 139712694728512] Epoch[135] Batch[0] avg_epoch_loss=1.213012\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:34 INFO 139712694728512] #quality_metric: host=algo-1, epoch=135, batch=0 train loss <loss>=1.21301245689\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:35 INFO 139712694728512] Epoch[135] Batch[5] avg_epoch_loss=1.158444\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=135, batch=5 train loss <loss>=1.15844426552\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:35 INFO 139712694728512] Epoch[135] Batch [5]#011Speed: 180.91 samples/sec#011loss=1.158444\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:37 INFO 139712694728512] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4017.0981884002686, \"sum\": 4017.0981884002686, \"min\": 4017.0981884002686}}, \"EndTime\": 1597163797.212634, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163793.195021}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:37 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.605501697 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:37 INFO 139712694728512] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=135, train loss <loss>=1.04065063596\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:37 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:38 INFO 139712694728512] Epoch[136] Batch[0] avg_epoch_loss=1.185432\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=136, batch=0 train loss <loss>=1.18543207645\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:39 INFO 139712694728512] Epoch[136] Batch[5] avg_epoch_loss=1.153148\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=136, batch=5 train loss <loss>=1.15314759811\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:39 INFO 139712694728512] Epoch[136] Batch [5]#011Speed: 180.78 samples/sec#011loss=1.153148\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] Epoch[136] Batch[10] avg_epoch_loss=1.260671\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=136, batch=10 train loss <loss>=1.38969819546\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] Epoch[136] Batch [10]#011Speed: 180.31 samples/sec#011loss=1.389698\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4406.193017959595, \"sum\": 4406.193017959595, \"min\": 4406.193017959595}}, \"EndTime\": 1597163801.619392, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163797.212729}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.648903014 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=136, train loss <loss>=1.2606705969\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:41 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:42 INFO 139712694728512] Epoch[137] Batch[0] avg_epoch_loss=1.045846\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=137, batch=0 train loss <loss>=1.04584574699\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:44 INFO 139712694728512] Epoch[137] Batch[5] avg_epoch_loss=1.130114\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=137, batch=5 train loss <loss>=1.13011406859\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:44 INFO 139712694728512] Epoch[137] Batch [5]#011Speed: 181.40 samples/sec#011loss=1.130114\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] Epoch[137] Batch[10] avg_epoch_loss=1.096664\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=137, batch=10 train loss <loss>=1.05652397275\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] Epoch[137] Batch [10]#011Speed: 176.44 samples/sec#011loss=1.056524\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] processed a total of 659 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4432.326078414917, \"sum\": 4432.326078414917, \"min\": 4432.326078414917}}, \"EndTime\": 1597163806.052287, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163801.619518}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.676238122 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=137, train loss <loss>=1.09666402502\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] Epoch[138] Batch[0] avg_epoch_loss=1.262230\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=138, batch=0 train loss <loss>=1.26222980022\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:48 INFO 139712694728512] Epoch[138] Batch[5] avg_epoch_loss=1.168587\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=138, batch=5 train loss <loss>=1.16858728727\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:48 INFO 139712694728512] Epoch[138] Batch [5]#011Speed: 179.39 samples/sec#011loss=1.168587\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:50 INFO 139712694728512] processed a total of 608 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4017.7340507507324, \"sum\": 4017.7340507507324, \"min\": 4017.7340507507324}}, \"EndTime\": 1597163810.070544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163806.052373}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:50 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.323926198 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:50 INFO 139712694728512] #progress_metric: host=algo-1, completed 34 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=138, train loss <loss>=1.12150884867\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:50 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:50 INFO 139712694728512] Epoch[139] Batch[0] avg_epoch_loss=1.034034\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=139, batch=0 train loss <loss>=1.03403353691\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:52 INFO 139712694728512] Epoch[139] Batch[5] avg_epoch_loss=1.127811\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=139, batch=5 train loss <loss>=1.12781081597\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:52 INFO 139712694728512] Epoch[139] Batch [5]#011Speed: 180.04 samples/sec#011loss=1.127811\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:54 INFO 139712694728512] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4066.7788982391357, \"sum\": 4066.7788982391357, \"min\": 4066.7788982391357}}, \"EndTime\": 1597163814.137889, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163810.07064}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:54 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.646313851 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:54 INFO 139712694728512] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=139, train loss <loss>=1.15589573383\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:54 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:54 INFO 139712694728512] Epoch[140] Batch[0] avg_epoch_loss=1.087171\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=140, batch=0 train loss <loss>=1.0871707201\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:56 INFO 139712694728512] Epoch[140] Batch[5] avg_epoch_loss=1.079726\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=140, batch=5 train loss <loss>=1.07972589135\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:56 INFO 139712694728512] Epoch[140] Batch [5]#011Speed: 182.31 samples/sec#011loss=1.079726\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:58 INFO 139712694728512] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3985.2850437164307, \"sum\": 3985.2850437164307, \"min\": 3985.2850437164307}}, \"EndTime\": 1597163818.123753, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163814.137983}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:58 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.316164893 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:58 INFO 139712694728512] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=140, train loss <loss>=1.08038576245\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:58 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:58 INFO 139712694728512] Epoch[141] Batch[0] avg_epoch_loss=1.211944\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:36:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=141, batch=0 train loss <loss>=1.21194434166\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:00 INFO 139712694728512] Epoch[141] Batch[5] avg_epoch_loss=1.039579\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=141, batch=5 train loss <loss>=1.03957897425\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:00 INFO 139712694728512] Epoch[141] Batch [5]#011Speed: 179.53 samples/sec#011loss=1.039579\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:02 INFO 139712694728512] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4123.619079589844, \"sum\": 4123.619079589844, \"min\": 4123.619079589844}}, \"EndTime\": 1597163822.247956, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163818.123848}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:02 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.228403591 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:02 INFO 139712694728512] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=141, train loss <loss>=1.08522256613\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:02 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:03 INFO 139712694728512] Epoch[142] Batch[0] avg_epoch_loss=1.163422\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=142, batch=0 train loss <loss>=1.16342246532\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:04 INFO 139712694728512] Epoch[142] Batch[5] avg_epoch_loss=1.090607\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=142, batch=5 train loss <loss>=1.09060733517\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:04 INFO 139712694728512] Epoch[142] Batch [5]#011Speed: 177.65 samples/sec#011loss=1.090607\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:06 INFO 139712694728512] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4044.901132583618, \"sum\": 4044.901132583618, \"min\": 4044.901132583618}}, \"EndTime\": 1597163826.293483, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163822.248048}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:06 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.97148078 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:06 INFO 139712694728512] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=142, train loss <loss>=1.09693942666\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:06 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:07 INFO 139712694728512] Epoch[143] Batch[0] avg_epoch_loss=1.001300\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=143, batch=0 train loss <loss>=1.00129961967\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:08 INFO 139712694728512] Epoch[143] Batch[5] avg_epoch_loss=0.982782\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=143, batch=5 train loss <loss>=0.982781648636\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:08 INFO 139712694728512] Epoch[143] Batch [5]#011Speed: 181.25 samples/sec#011loss=0.982782\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:10 INFO 139712694728512] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4091.2649631500244, \"sum\": 4091.2649631500244, \"min\": 4091.2649631500244}}, \"EndTime\": 1597163830.385334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163826.293575}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:10 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.048570642 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:10 INFO 139712694728512] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=143, train loss <loss>=0.964668959379\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:10 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:10 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_52f48f7b-e5cd-457d-a540-b7d92bc952fc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 121.96683883666992, \"sum\": 121.96683883666992, \"min\": 121.96683883666992}}, \"EndTime\": 1597163830.507921, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163830.385428}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:11 INFO 139712694728512] Epoch[144] Batch[0] avg_epoch_loss=1.061467\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=144, batch=0 train loss <loss>=1.06146657467\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:13 INFO 139712694728512] Epoch[144] Batch[5] avg_epoch_loss=1.060526\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=144, batch=5 train loss <loss>=1.0605255266\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:13 INFO 139712694728512] Epoch[144] Batch [5]#011Speed: 181.14 samples/sec#011loss=1.060526\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] Epoch[144] Batch[10] avg_epoch_loss=1.008227\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=144, batch=10 train loss <loss>=0.94546970129\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] Epoch[144] Batch [10]#011Speed: 174.58 samples/sec#011loss=0.945470\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4430.218935012817, \"sum\": 4430.218935012817, \"min\": 4430.218935012817}}, \"EndTime\": 1597163834.938292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163830.507998}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.680877431 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=144, train loss <loss>=1.00822742419\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:14 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:15 INFO 139712694728512] Epoch[145] Batch[0] avg_epoch_loss=1.230642\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=145, batch=0 train loss <loss>=1.23064184189\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:17 INFO 139712694728512] Epoch[145] Batch[5] avg_epoch_loss=1.126307\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=145, batch=5 train loss <loss>=1.12630742788\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:17 INFO 139712694728512] Epoch[145] Batch [5]#011Speed: 181.64 samples/sec#011loss=1.126307\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:18 INFO 139712694728512] processed a total of 618 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3988.9328479766846, \"sum\": 3988.9328479766846, \"min\": 3988.9328479766846}}, \"EndTime\": 1597163838.927908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163834.938383}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:18 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.923561863 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:18 INFO 139712694728512] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=145, train loss <loss>=1.10393586159\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:18 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:19 INFO 139712694728512] Epoch[146] Batch[0] avg_epoch_loss=1.125934\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=146, batch=0 train loss <loss>=1.12593364716\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:21 INFO 139712694728512] Epoch[146] Batch[5] avg_epoch_loss=1.125972\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=146, batch=5 train loss <loss>=1.12597193321\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:21 INFO 139712694728512] Epoch[146] Batch [5]#011Speed: 179.15 samples/sec#011loss=1.125972\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:23 INFO 139712694728512] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4081.3910961151123, \"sum\": 4081.3910961151123, \"min\": 4081.3910961151123}}, \"EndTime\": 1597163843.009869, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163838.928001}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:23 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.843935978 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:23 INFO 139712694728512] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=146, train loss <loss>=1.12459720373\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:23 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:23 INFO 139712694728512] Epoch[147] Batch[0] avg_epoch_loss=1.136371\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=147, batch=0 train loss <loss>=1.13637065887\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:25 INFO 139712694728512] Epoch[147] Batch[5] avg_epoch_loss=1.094931\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=147, batch=5 train loss <loss>=1.09493062894\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:25 INFO 139712694728512] Epoch[147] Batch [5]#011Speed: 177.95 samples/sec#011loss=1.094931\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] Epoch[147] Batch[10] avg_epoch_loss=1.068235\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=147, batch=10 train loss <loss>=1.03620132208\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] Epoch[147] Batch [10]#011Speed: 178.13 samples/sec#011loss=1.036201\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4425.416946411133, \"sum\": 4425.416946411133, \"min\": 4425.416946411133}}, \"EndTime\": 1597163847.435908, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163843.009964}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.783438814 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=147, train loss <loss>=1.06823548946\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:27 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:28 INFO 139712694728512] Epoch[148] Batch[0] avg_epoch_loss=1.111218\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=148, batch=0 train loss <loss>=1.11121797562\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:30 INFO 139712694728512] Epoch[148] Batch[5] avg_epoch_loss=0.932668\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:30 INFO 139712694728512] #quality_metric: host=algo-1, epoch=148, batch=5 train loss <loss>=0.932668010394\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:30 INFO 139712694728512] Epoch[148] Batch [5]#011Speed: 179.62 samples/sec#011loss=0.932668\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:31 INFO 139712694728512] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4050.2870082855225, \"sum\": 4050.2870082855225, \"min\": 4050.2870082855225}}, \"EndTime\": 1597163851.486718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163847.435991}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:31 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.79872341 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:31 INFO 139712694728512] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=148, train loss <loss>=0.930877500772\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:31 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:31 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_c379a84c-d9e5-428c-a3ed-440c687e2dd2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 121.64807319641113, \"sum\": 121.64807319641113, \"min\": 121.64807319641113}}, \"EndTime\": 1597163851.609009, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163851.486812}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:32 INFO 139712694728512] Epoch[149] Batch[0] avg_epoch_loss=0.866502\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=149, batch=0 train loss <loss>=0.866501629353\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:34 INFO 139712694728512] Epoch[149] Batch[5] avg_epoch_loss=0.998818\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:34 INFO 139712694728512] #quality_metric: host=algo-1, epoch=149, batch=5 train loss <loss>=0.998817722003\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:34 INFO 139712694728512] Epoch[149] Batch [5]#011Speed: 183.59 samples/sec#011loss=0.998818\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] Epoch[149] Batch[10] avg_epoch_loss=1.087973\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=149, batch=10 train loss <loss>=1.19495840073\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] Epoch[149] Batch [10]#011Speed: 179.40 samples/sec#011loss=1.194958\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4376.260995864868, \"sum\": 4376.260995864868, \"min\": 4376.260995864868}}, \"EndTime\": 1597163855.985398, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163851.609067}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.551600077 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=149, train loss <loss>=1.08797257597\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:35 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:36 INFO 139712694728512] Epoch[150] Batch[0] avg_epoch_loss=1.243900\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=150, batch=0 train loss <loss>=1.24389958382\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:38 INFO 139712694728512] Epoch[150] Batch[5] avg_epoch_loss=1.239033\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=150, batch=5 train loss <loss>=1.23903340101\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:38 INFO 139712694728512] Epoch[150] Batch [5]#011Speed: 180.85 samples/sec#011loss=1.239033\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:39 INFO 139712694728512] processed a total of 620 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4005.418062210083, \"sum\": 4005.418062210083, \"min\": 4005.418062210083}}, \"EndTime\": 1597163859.991386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163855.985474}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:39 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.784234828 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:39 INFO 139712694728512] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=150, train loss <loss>=1.17977901697\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:39 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:40 INFO 139712694728512] Epoch[151] Batch[0] avg_epoch_loss=1.065940\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=151, batch=0 train loss <loss>=1.06594026089\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:42 INFO 139712694728512] Epoch[151] Batch[5] avg_epoch_loss=1.102599\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=151, batch=5 train loss <loss>=1.10259858767\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:42 INFO 139712694728512] Epoch[151] Batch [5]#011Speed: 181.66 samples/sec#011loss=1.102599\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:44 INFO 139712694728512] processed a total of 606 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4009.5109939575195, \"sum\": 4009.5109939575195, \"min\": 4009.5109939575195}}, \"EndTime\": 1597163864.001493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163859.991502}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:44 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.135799572 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:44 INFO 139712694728512] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=151, train loss <loss>=1.04720793962\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:44 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:44 INFO 139712694728512] Epoch[152] Batch[0] avg_epoch_loss=0.987609\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=152, batch=0 train loss <loss>=0.987609267235\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:46 INFO 139712694728512] Epoch[152] Batch[5] avg_epoch_loss=1.072716\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=152, batch=5 train loss <loss>=1.0727164348\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:46 INFO 139712694728512] Epoch[152] Batch [5]#011Speed: 177.43 samples/sec#011loss=1.072716\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] Epoch[152] Batch[10] avg_epoch_loss=1.134112\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=152, batch=10 train loss <loss>=1.20778763294\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] Epoch[152] Batch [10]#011Speed: 177.44 samples/sec#011loss=1.207788\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4469.477891921997, \"sum\": 4469.477891921997, \"min\": 4469.477891921997}}, \"EndTime\": 1597163868.471549, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163864.001582}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=145.426846279 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=152, train loss <loss>=1.13411243395\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:48 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:49 INFO 139712694728512] Epoch[153] Batch[0] avg_epoch_loss=1.290933\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=153, batch=0 train loss <loss>=1.29093253613\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:51 INFO 139712694728512] Epoch[153] Batch[5] avg_epoch_loss=1.102671\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=153, batch=5 train loss <loss>=1.10267067949\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:51 INFO 139712694728512] Epoch[153] Batch [5]#011Speed: 179.08 samples/sec#011loss=1.102671\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:52 INFO 139712694728512] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4059.5200061798096, \"sum\": 4059.5200061798096, \"min\": 4059.5200061798096}}, \"EndTime\": 1597163872.531591, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163868.471635}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:52 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.954052223 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:52 INFO 139712694728512] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=153, train loss <loss>=1.08038882017\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:52 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:53 INFO 139712694728512] Epoch[154] Batch[0] avg_epoch_loss=0.837958\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:53 INFO 139712694728512] #quality_metric: host=algo-1, epoch=154, batch=0 train loss <loss>=0.837958455086\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:55 INFO 139712694728512] Epoch[154] Batch[5] avg_epoch_loss=1.075024\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=154, batch=5 train loss <loss>=1.07502424717\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:55 INFO 139712694728512] Epoch[154] Batch [5]#011Speed: 180.64 samples/sec#011loss=1.075024\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] Epoch[154] Batch[10] avg_epoch_loss=1.108284\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=154, batch=10 train loss <loss>=1.14819562435\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] Epoch[154] Batch [10]#011Speed: 180.57 samples/sec#011loss=1.148196\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4463.219881057739, \"sum\": 4463.219881057739, \"min\": 4463.219881057739}}, \"EndTime\": 1597163876.995386, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163872.531684}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.526256143 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=154, train loss <loss>=1.10828396407\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:56 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:57 INFO 139712694728512] Epoch[155] Batch[0] avg_epoch_loss=1.362607\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=155, batch=0 train loss <loss>=1.36260712147\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:59 INFO 139712694728512] Epoch[155] Batch[5] avg_epoch_loss=1.090745\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=155, batch=5 train loss <loss>=1.09074544907\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:37:59 INFO 139712694728512] Epoch[155] Batch [5]#011Speed: 182.10 samples/sec#011loss=1.090745\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] Epoch[155] Batch[10] avg_epoch_loss=1.035343\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=155, batch=10 train loss <loss>=0.968860137463\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] Epoch[155] Batch [10]#011Speed: 181.48 samples/sec#011loss=0.968860\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4393.860101699829, \"sum\": 4393.860101699829, \"min\": 4393.860101699829}}, \"EndTime\": 1597163881.38982, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163876.995491}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.612322067 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=155, train loss <loss>=1.0353430347\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:01 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:02 INFO 139712694728512] Epoch[156] Batch[0] avg_epoch_loss=1.083451\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=156, batch=0 train loss <loss>=1.08345079422\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:03 INFO 139712694728512] Epoch[156] Batch[5] avg_epoch_loss=1.027240\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=156, batch=5 train loss <loss>=1.02723978957\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:03 INFO 139712694728512] Epoch[156] Batch [5]#011Speed: 183.35 samples/sec#011loss=1.027240\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:05 INFO 139712694728512] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3991.788148880005, \"sum\": 3991.788148880005, \"min\": 3991.788148880005}}, \"EndTime\": 1597163885.382132, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163881.389906}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:05 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.554002639 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:05 INFO 139712694728512] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=156, train loss <loss>=1.03694899678\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:05 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:06 INFO 139712694728512] Epoch[157] Batch[0] avg_epoch_loss=1.186815\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=157, batch=0 train loss <loss>=1.18681454659\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:07 INFO 139712694728512] Epoch[157] Batch[5] avg_epoch_loss=1.050573\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=157, batch=5 train loss <loss>=1.05057329933\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:07 INFO 139712694728512] Epoch[157] Batch [5]#011Speed: 180.74 samples/sec#011loss=1.050573\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] Epoch[157] Batch[10] avg_epoch_loss=1.028537\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=157, batch=10 train loss <loss>=1.00209434032\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] Epoch[157] Batch [10]#011Speed: 178.62 samples/sec#011loss=1.002094\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4398.275852203369, \"sum\": 4398.275852203369, \"min\": 4398.275852203369}}, \"EndTime\": 1597163889.781011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163885.382226}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.467116431 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=157, train loss <loss>=1.02853740887\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:09 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:10 INFO 139712694728512] Epoch[158] Batch[0] avg_epoch_loss=1.066221\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=158, batch=0 train loss <loss>=1.06622099876\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:12 INFO 139712694728512] Epoch[158] Batch[5] avg_epoch_loss=1.115412\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=158, batch=5 train loss <loss>=1.11541218559\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:12 INFO 139712694728512] Epoch[158] Batch [5]#011Speed: 180.22 samples/sec#011loss=1.115412\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:13 INFO 139712694728512] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4007.434129714966, \"sum\": 4007.434129714966, \"min\": 4007.434129714966}}, \"EndTime\": 1597163893.789016, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163889.781084}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:13 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.705363621 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:13 INFO 139712694728512] #progress_metric: host=algo-1, completed 39 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=158, train loss <loss>=1.09911943078\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:13 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:14 INFO 139712694728512] Epoch[159] Batch[0] avg_epoch_loss=1.113114\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=159, batch=0 train loss <loss>=1.11311411858\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:16 INFO 139712694728512] Epoch[159] Batch[5] avg_epoch_loss=1.039195\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=159, batch=5 train loss <loss>=1.03919541836\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:16 INFO 139712694728512] Epoch[159] Batch [5]#011Speed: 177.59 samples/sec#011loss=1.039195\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:17 INFO 139712694728512] processed a total of 585 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4073.0531215667725, \"sum\": 4073.0531215667725, \"min\": 4073.0531215667725}}, \"EndTime\": 1597163897.862629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163893.789111}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:17 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=143.622714918 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:17 INFO 139712694728512] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:17 INFO 139712694728512] #quality_metric: host=algo-1, epoch=159, train loss <loss>=1.07895981073\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:17 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:18 INFO 139712694728512] Epoch[160] Batch[0] avg_epoch_loss=0.895923\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=160, batch=0 train loss <loss>=0.895922780037\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:20 INFO 139712694728512] Epoch[160] Batch[5] avg_epoch_loss=0.987843\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=160, batch=5 train loss <loss>=0.987843394279\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:20 INFO 139712694728512] Epoch[160] Batch [5]#011Speed: 177.77 samples/sec#011loss=0.987843\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] Epoch[160] Batch[10] avg_epoch_loss=1.050359\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=160, batch=10 train loss <loss>=1.12537841797\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] Epoch[160] Batch [10]#011Speed: 179.19 samples/sec#011loss=1.125378\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4422.461986541748, \"sum\": 4422.461986541748, \"min\": 4422.461986541748}}, \"EndTime\": 1597163902.285703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163897.862706}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.947259885 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=160, train loss <loss>=1.05035931414\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:22 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:23 INFO 139712694728512] Epoch[161] Batch[0] avg_epoch_loss=0.960754\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=161, batch=0 train loss <loss>=0.960753858089\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:24 INFO 139712694728512] Epoch[161] Batch[5] avg_epoch_loss=1.071934\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=161, batch=5 train loss <loss>=1.0719344914\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:24 INFO 139712694728512] Epoch[161] Batch [5]#011Speed: 178.22 samples/sec#011loss=1.071934\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] Epoch[161] Batch[10] avg_epoch_loss=1.046453\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=161, batch=10 train loss <loss>=1.01587486267\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] Epoch[161] Batch [10]#011Speed: 180.03 samples/sec#011loss=1.015875\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] processed a total of 698 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4404.755115509033, \"sum\": 4404.755115509033, \"min\": 4404.755115509033}}, \"EndTime\": 1597163906.690998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163902.285791}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.46108645 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=161, train loss <loss>=1.04645284198\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:26 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:27 INFO 139712694728512] Epoch[162] Batch[0] avg_epoch_loss=1.299434\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=162, batch=0 train loss <loss>=1.29943394661\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:29 INFO 139712694728512] Epoch[162] Batch[5] avg_epoch_loss=1.060289\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=162, batch=5 train loss <loss>=1.06028879682\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:29 INFO 139712694728512] Epoch[162] Batch [5]#011Speed: 180.97 samples/sec#011loss=1.060289\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] Epoch[162] Batch[10] avg_epoch_loss=1.089356\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=162, batch=10 train loss <loss>=1.12423727512\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] Epoch[162] Batch [10]#011Speed: 177.15 samples/sec#011loss=1.124237\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4390.190839767456, \"sum\": 4390.190839767456, \"min\": 4390.190839767456}}, \"EndTime\": 1597163911.081762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163906.691076}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.003252688 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=162, train loss <loss>=1.08935628696\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] Epoch[163] Batch[0] avg_epoch_loss=1.010671\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=163, batch=0 train loss <loss>=1.01067078114\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:33 INFO 139712694728512] Epoch[163] Batch[5] avg_epoch_loss=1.067133\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=163, batch=5 train loss <loss>=1.06713275115\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:33 INFO 139712694728512] Epoch[163] Batch [5]#011Speed: 181.11 samples/sec#011loss=1.067133\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] Epoch[163] Batch[10] avg_epoch_loss=1.016856\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=163, batch=10 train loss <loss>=0.956523561478\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] Epoch[163] Batch [10]#011Speed: 180.01 samples/sec#011loss=0.956524\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4367.375135421753, \"sum\": 4367.375135421753, \"min\": 4367.375135421753}}, \"EndTime\": 1597163915.449697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163911.081844}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.200242758 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=163, train loss <loss>=1.01685584675\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:35 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:36 INFO 139712694728512] Epoch[164] Batch[0] avg_epoch_loss=1.030447\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=164, batch=0 train loss <loss>=1.03044748306\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:38 INFO 139712694728512] Epoch[164] Batch[5] avg_epoch_loss=1.162939\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=164, batch=5 train loss <loss>=1.16293907166\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:38 INFO 139712694728512] Epoch[164] Batch [5]#011Speed: 180.53 samples/sec#011loss=1.162939\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:39 INFO 139712694728512] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4054.3642044067383, \"sum\": 4054.3642044067383, \"min\": 4054.3642044067383}}, \"EndTime\": 1597163919.504621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163915.449785}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:39 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.889624873 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:39 INFO 139712694728512] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=164, train loss <loss>=1.05023958683\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:39 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:40 INFO 139712694728512] Epoch[165] Batch[0] avg_epoch_loss=1.208059\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=165, batch=0 train loss <loss>=1.2080591917\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:42 INFO 139712694728512] Epoch[165] Batch[5] avg_epoch_loss=1.056523\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=165, batch=5 train loss <loss>=1.05652261774\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:42 INFO 139712694728512] Epoch[165] Batch [5]#011Speed: 179.37 samples/sec#011loss=1.056523\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:43 INFO 139712694728512] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4114.4468784332275, \"sum\": 4114.4468784332275, \"min\": 4114.4468784332275}}, \"EndTime\": 1597163923.619665, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163919.504716}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:43 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.114042346 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:43 INFO 139712694728512] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=165, train loss <loss>=1.1208927691\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:43 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:44 INFO 139712694728512] Epoch[166] Batch[0] avg_epoch_loss=1.115068\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=166, batch=0 train loss <loss>=1.11506772041\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:46 INFO 139712694728512] Epoch[166] Batch[5] avg_epoch_loss=0.948985\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=166, batch=5 train loss <loss>=0.948985050122\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:46 INFO 139712694728512] Epoch[166] Batch [5]#011Speed: 176.21 samples/sec#011loss=0.948985\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:47 INFO 139712694728512] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4055.5639266967773, \"sum\": 4055.5639266967773, \"min\": 4055.5639266967773}}, \"EndTime\": 1597163927.675845, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163923.619757}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:47 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.145903498 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:47 INFO 139712694728512] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:47 INFO 139712694728512] #quality_metric: host=algo-1, epoch=166, train loss <loss>=1.12000430822\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:47 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:48 INFO 139712694728512] Epoch[167] Batch[0] avg_epoch_loss=1.035783\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=167, batch=0 train loss <loss>=1.03578341007\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:50 INFO 139712694728512] Epoch[167] Batch[5] avg_epoch_loss=1.136900\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=167, batch=5 train loss <loss>=1.13690026601\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:50 INFO 139712694728512] Epoch[167] Batch [5]#011Speed: 178.29 samples/sec#011loss=1.136900\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:51 INFO 139712694728512] processed a total of 603 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4069.4432258605957, \"sum\": 4069.4432258605957, \"min\": 4069.4432258605957}}, \"EndTime\": 1597163931.745866, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163927.675931}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:51 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.172535845 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:51 INFO 139712694728512] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=167, train loss <loss>=1.12142962217\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:51 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:52 INFO 139712694728512] Epoch[168] Batch[0] avg_epoch_loss=0.930664\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=168, batch=0 train loss <loss>=0.930664300919\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:54 INFO 139712694728512] Epoch[168] Batch[5] avg_epoch_loss=1.074099\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=168, batch=5 train loss <loss>=1.07409928242\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:54 INFO 139712694728512] Epoch[168] Batch [5]#011Speed: 180.34 samples/sec#011loss=1.074099\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:55 INFO 139712694728512] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4040.0497913360596, \"sum\": 4040.0497913360596, \"min\": 4040.0497913360596}}, \"EndTime\": 1597163935.786544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163931.745962}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:55 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.181087755 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:55 INFO 139712694728512] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=168, train loss <loss>=1.0590359509\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:55 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:56 INFO 139712694728512] Epoch[169] Batch[0] avg_epoch_loss=1.102757\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:56 INFO 139712694728512] #quality_metric: host=algo-1, epoch=169, batch=0 train loss <loss>=1.10275709629\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:58 INFO 139712694728512] Epoch[169] Batch[5] avg_epoch_loss=1.041215\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=169, batch=5 train loss <loss>=1.04121523102\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:58 INFO 139712694728512] Epoch[169] Batch [5]#011Speed: 183.30 samples/sec#011loss=1.041215\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:59 INFO 139712694728512] processed a total of 635 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3970.13521194458, \"sum\": 3970.13521194458, \"min\": 3970.13521194458}}, \"EndTime\": 1597163939.757234, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163935.786638}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:59 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=159.938988118 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:59 INFO 139712694728512] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=169, train loss <loss>=1.03200520873\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:38:59 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:00 INFO 139712694728512] Epoch[170] Batch[0] avg_epoch_loss=1.034919\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=170, batch=0 train loss <loss>=1.03491914272\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:02 INFO 139712694728512] Epoch[170] Batch[5] avg_epoch_loss=0.993256\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=170, batch=5 train loss <loss>=0.99325616161\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:02 INFO 139712694728512] Epoch[170] Batch [5]#011Speed: 178.79 samples/sec#011loss=0.993256\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:03 INFO 139712694728512] processed a total of 612 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4018.5458660125732, \"sum\": 4018.5458660125732, \"min\": 4018.5458660125732}}, \"EndTime\": 1597163943.776356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163939.757324}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:03 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.290135772 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:03 INFO 139712694728512] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=170, train loss <loss>=0.939488351345\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:03 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:04 INFO 139712694728512] Epoch[171] Batch[0] avg_epoch_loss=0.963876\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=171, batch=0 train loss <loss>=0.963875830173\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:06 INFO 139712694728512] Epoch[171] Batch[5] avg_epoch_loss=0.970258\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=171, batch=5 train loss <loss>=0.970258265734\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:06 INFO 139712694728512] Epoch[171] Batch [5]#011Speed: 180.26 samples/sec#011loss=0.970258\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] Epoch[171] Batch[10] avg_epoch_loss=0.992003\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=171, batch=10 train loss <loss>=1.01809661388\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] Epoch[171] Batch [10]#011Speed: 181.65 samples/sec#011loss=1.018097\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4350.077152252197, \"sum\": 4350.077152252197, \"min\": 4350.077152252197}}, \"EndTime\": 1597163948.12699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163943.776424}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.31472297 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=171, train loss <loss>=0.992002969438\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] Epoch[172] Batch[0] avg_epoch_loss=0.905280\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=172, batch=0 train loss <loss>=0.90528023243\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:10 INFO 139712694728512] Epoch[172] Batch[5] avg_epoch_loss=1.026230\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=172, batch=5 train loss <loss>=1.02623049418\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:10 INFO 139712694728512] Epoch[172] Batch [5]#011Speed: 180.95 samples/sec#011loss=1.026230\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:12 INFO 139712694728512] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3977.8101444244385, \"sum\": 3977.8101444244385, \"min\": 3977.8101444244385}}, \"EndTime\": 1597163952.105376, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163948.127071}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:12 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.373388208 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:12 INFO 139712694728512] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=172, train loss <loss>=1.02539645433\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:12 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:12 INFO 139712694728512] Epoch[173] Batch[0] avg_epoch_loss=1.213286\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=173, batch=0 train loss <loss>=1.21328556538\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:14 INFO 139712694728512] Epoch[173] Batch[5] avg_epoch_loss=1.055589\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=173, batch=5 train loss <loss>=1.05558893085\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:14 INFO 139712694728512] Epoch[173] Batch [5]#011Speed: 182.66 samples/sec#011loss=1.055589\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:16 INFO 139712694728512] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4031.8119525909424, \"sum\": 4031.8119525909424, \"min\": 4031.8119525909424}}, \"EndTime\": 1597163956.137755, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163952.105467}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:16 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.269236621 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:16 INFO 139712694728512] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=173, train loss <loss>=1.04760062099\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:16 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:16 INFO 139712694728512] Epoch[174] Batch[0] avg_epoch_loss=0.919413\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=174, batch=0 train loss <loss>=0.919413030148\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:18 INFO 139712694728512] Epoch[174] Batch[5] avg_epoch_loss=1.028444\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=174, batch=5 train loss <loss>=1.02844401201\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:18 INFO 139712694728512] Epoch[174] Batch [5]#011Speed: 181.64 samples/sec#011loss=1.028444\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] Epoch[174] Batch[10] avg_epoch_loss=1.021873\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=174, batch=10 train loss <loss>=1.01398808956\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] Epoch[174] Batch [10]#011Speed: 181.08 samples/sec#011loss=1.013988\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4335.93487739563, \"sum\": 4335.93487739563, \"min\": 4335.93487739563}}, \"EndTime\": 1597163960.474401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163956.137824}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.291336935 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=174, train loss <loss>=1.02187313817\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:20 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:21 INFO 139712694728512] Epoch[175] Batch[0] avg_epoch_loss=1.021686\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=175, batch=0 train loss <loss>=1.02168643475\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:23 INFO 139712694728512] Epoch[175] Batch[5] avg_epoch_loss=1.128062\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:23 INFO 139712694728512] #quality_metric: host=algo-1, epoch=175, batch=5 train loss <loss>=1.1280618906\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:23 INFO 139712694728512] Epoch[175] Batch [5]#011Speed: 181.36 samples/sec#011loss=1.128062\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] Epoch[175] Batch[10] avg_epoch_loss=1.115168\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=175, batch=10 train loss <loss>=1.09969438314\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] Epoch[175] Batch [10]#011Speed: 180.66 samples/sec#011loss=1.099694\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4361.0711097717285, \"sum\": 4361.0711097717285, \"min\": 4361.0711097717285}}, \"EndTime\": 1597163964.836071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163960.474487}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.435974403 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=175, train loss <loss>=1.11516756903\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:24 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:25 INFO 139712694728512] Epoch[176] Batch[0] avg_epoch_loss=1.041078\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=176, batch=0 train loss <loss>=1.04107785225\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:27 INFO 139712694728512] Epoch[176] Batch[5] avg_epoch_loss=1.107060\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=176, batch=5 train loss <loss>=1.1070599854\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:27 INFO 139712694728512] Epoch[176] Batch [5]#011Speed: 181.86 samples/sec#011loss=1.107060\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:28 INFO 139712694728512] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4027.4009704589844, \"sum\": 4027.4009704589844, \"min\": 4027.4009704589844}}, \"EndTime\": 1597163968.863996, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163964.836156}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:28 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.919730483 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:28 INFO 139712694728512] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=176, train loss <loss>=1.0654063046\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:28 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:29 INFO 139712694728512] Epoch[177] Batch[0] avg_epoch_loss=1.024301\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=177, batch=0 train loss <loss>=1.02430081367\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:31 INFO 139712694728512] Epoch[177] Batch[5] avg_epoch_loss=0.943426\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=177, batch=5 train loss <loss>=0.943426311016\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:31 INFO 139712694728512] Epoch[177] Batch [5]#011Speed: 180.01 samples/sec#011loss=0.943426\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] Epoch[177] Batch[10] avg_epoch_loss=0.902268\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=177, batch=10 train loss <loss>=0.852879041433\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] Epoch[177] Batch [10]#011Speed: 180.36 samples/sec#011loss=0.852879\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4393.492937088013, \"sum\": 4393.492937088013, \"min\": 4393.492937088013}}, \"EndTime\": 1597163973.258053, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163968.864089}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.720964937 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=177, train loss <loss>=0.902268461206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:33 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/state_1c2b5bd2-ba62-421c-8413-efdaae842811-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 125.34093856811523, \"sum\": 125.34093856811523, \"min\": 125.34093856811523}}, \"EndTime\": 1597163973.383988, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163973.258158}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:34 INFO 139712694728512] Epoch[178] Batch[0] avg_epoch_loss=0.957317\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:34 INFO 139712694728512] #quality_metric: host=algo-1, epoch=178, batch=0 train loss <loss>=0.957316935062\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:35 INFO 139712694728512] Epoch[178] Batch[5] avg_epoch_loss=1.067385\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=178, batch=5 train loss <loss>=1.06738463044\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:35 INFO 139712694728512] Epoch[178] Batch [5]#011Speed: 181.32 samples/sec#011loss=1.067385\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] Epoch[178] Batch[10] avg_epoch_loss=0.954013\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=178, batch=10 train loss <loss>=0.817967532575\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] Epoch[178] Batch [10]#011Speed: 182.41 samples/sec#011loss=0.817968\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4349.648952484131, \"sum\": 4349.648952484131, \"min\": 4349.648952484131}}, \"EndTime\": 1597163977.733766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163973.384058}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.28380566 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] #progress_metric: host=algo-1, completed 44 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=178, train loss <loss>=0.954013222321\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:37 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:38 INFO 139712694728512] Epoch[179] Batch[0] avg_epoch_loss=0.999042\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:38 INFO 139712694728512] #quality_metric: host=algo-1, epoch=179, batch=0 train loss <loss>=0.999042451382\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:40 INFO 139712694728512] Epoch[179] Batch[5] avg_epoch_loss=1.010574\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=179, batch=5 train loss <loss>=1.01057392359\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:40 INFO 139712694728512] Epoch[179] Batch [5]#011Speed: 181.01 samples/sec#011loss=1.010574\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:41 INFO 139712694728512] processed a total of 600 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4041.0139560699463, \"sum\": 4041.0139560699463, \"min\": 4041.0139560699463}}, \"EndTime\": 1597163981.775283, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163977.733849}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:41 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.47317172 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:41 INFO 139712694728512] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=179, train loss <loss>=1.06186282039\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:41 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:42 INFO 139712694728512] Epoch[180] Batch[0] avg_epoch_loss=1.088253\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=180, batch=0 train loss <loss>=1.0882525444\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:44 INFO 139712694728512] Epoch[180] Batch[5] avg_epoch_loss=1.087007\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:44 INFO 139712694728512] #quality_metric: host=algo-1, epoch=180, batch=5 train loss <loss>=1.08700746298\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:44 INFO 139712694728512] Epoch[180] Batch [5]#011Speed: 182.33 samples/sec#011loss=1.087007\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] Epoch[180] Batch[10] avg_epoch_loss=1.126789\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=180, batch=10 train loss <loss>=1.17452721596\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] Epoch[180] Batch [10]#011Speed: 176.59 samples/sec#011loss=1.174527\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] processed a total of 693 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4383.725166320801, \"sum\": 4383.725166320801, \"min\": 4383.725166320801}}, \"EndTime\": 1597163986.159624, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163981.77537}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.08091055 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=180, train loss <loss>=1.12678916888\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] Epoch[181] Batch[0] avg_epoch_loss=1.109972\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=181, batch=0 train loss <loss>=1.10997247696\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:48 INFO 139712694728512] Epoch[181] Batch[5] avg_epoch_loss=1.038309\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=181, batch=5 train loss <loss>=1.03830943505\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:48 INFO 139712694728512] Epoch[181] Batch [5]#011Speed: 182.48 samples/sec#011loss=1.038309\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] Epoch[181] Batch[10] avg_epoch_loss=1.059190\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=181, batch=10 train loss <loss>=1.08424569368\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] Epoch[181] Batch [10]#011Speed: 179.63 samples/sec#011loss=1.084246\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4339.842081069946, \"sum\": 4339.842081069946, \"min\": 4339.842081069946}}, \"EndTime\": 1597163990.500001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163986.15969}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.001412067 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=181, train loss <loss>=1.05918955261\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:50 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:51 INFO 139712694728512] Epoch[182] Batch[0] avg_epoch_loss=1.084534\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=182, batch=0 train loss <loss>=1.08453416824\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:53 INFO 139712694728512] Epoch[182] Batch[5] avg_epoch_loss=1.037371\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:53 INFO 139712694728512] #quality_metric: host=algo-1, epoch=182, batch=5 train loss <loss>=1.03737119834\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:53 INFO 139712694728512] Epoch[182] Batch [5]#011Speed: 181.43 samples/sec#011loss=1.037371\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] Epoch[182] Batch[10] avg_epoch_loss=1.027905\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=182, batch=10 train loss <loss>=1.01654587984\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] Epoch[182] Batch [10]#011Speed: 183.26 samples/sec#011loss=1.016546\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4325.5250453948975, \"sum\": 4325.5250453948975, \"min\": 4325.5250453948975}}, \"EndTime\": 1597163994.826082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163990.500081}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.04061806 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=182, train loss <loss>=1.02790514447\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:54 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:55 INFO 139712694728512] Epoch[183] Batch[0] avg_epoch_loss=0.896489\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=183, batch=0 train loss <loss>=0.896488547325\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:57 INFO 139712694728512] Epoch[183] Batch[5] avg_epoch_loss=0.917252\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=183, batch=5 train loss <loss>=0.917251696189\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:57 INFO 139712694728512] Epoch[183] Batch [5]#011Speed: 180.66 samples/sec#011loss=0.917252\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:58 INFO 139712694728512] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4025.1150131225586, \"sum\": 4025.1150131225586, \"min\": 4025.1150131225586}}, \"EndTime\": 1597163998.851721, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163994.826169}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:58 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.015239133 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:58 INFO 139712694728512] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=183, train loss <loss>=0.931855380535\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:58 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:59 INFO 139712694728512] Epoch[184] Batch[0] avg_epoch_loss=1.089821\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:39:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=184, batch=0 train loss <loss>=1.08982121944\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:01 INFO 139712694728512] Epoch[184] Batch[5] avg_epoch_loss=1.026854\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=184, batch=5 train loss <loss>=1.02685405811\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:01 INFO 139712694728512] Epoch[184] Batch [5]#011Speed: 178.66 samples/sec#011loss=1.026854\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:02 INFO 139712694728512] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4063.302993774414, \"sum\": 4063.302993774414, \"min\": 4063.302993774414}}, \"EndTime\": 1597164002.915645, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597163998.851813}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:02 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.517709781 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:02 INFO 139712694728512] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=184, train loss <loss>=1.00953214169\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:02 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:03 INFO 139712694728512] Epoch[185] Batch[0] avg_epoch_loss=0.817370\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=185, batch=0 train loss <loss>=0.817369699478\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:05 INFO 139712694728512] Epoch[185] Batch[5] avg_epoch_loss=0.963928\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=185, batch=5 train loss <loss>=0.963928252459\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:05 INFO 139712694728512] Epoch[185] Batch [5]#011Speed: 180.40 samples/sec#011loss=0.963928\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] Epoch[185] Batch[10] avg_epoch_loss=0.947951\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=185, batch=10 train loss <loss>=0.928778588772\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] Epoch[185] Batch [10]#011Speed: 178.99 samples/sec#011loss=0.928779\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4404.466152191162, \"sum\": 4404.466152191162, \"min\": 4404.466152191162}}, \"EndTime\": 1597164007.320736, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164002.915741}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=150.979073261 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=185, train loss <loss>=0.947951132601\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:07 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:08 INFO 139712694728512] Epoch[186] Batch[0] avg_epoch_loss=1.102598\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=186, batch=0 train loss <loss>=1.1025980711\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:09 INFO 139712694728512] Epoch[186] Batch[5] avg_epoch_loss=1.024374\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:09 INFO 139712694728512] #quality_metric: host=algo-1, epoch=186, batch=5 train loss <loss>=1.02437448502\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:09 INFO 139712694728512] Epoch[186] Batch [5]#011Speed: 178.88 samples/sec#011loss=1.024374\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:11 INFO 139712694728512] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4067.9571628570557, \"sum\": 4067.9571628570557, \"min\": 4067.9571628570557}}, \"EndTime\": 1597164011.389194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164007.320817}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:11 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.33872553 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:11 INFO 139712694728512] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=186, train loss <loss>=1.03521108031\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:11 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:12 INFO 139712694728512] Epoch[187] Batch[0] avg_epoch_loss=0.912539\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=187, batch=0 train loss <loss>=0.912539243698\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:13 INFO 139712694728512] Epoch[187] Batch[5] avg_epoch_loss=1.024517\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:13 INFO 139712694728512] #quality_metric: host=algo-1, epoch=187, batch=5 train loss <loss>=1.02451700966\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:13 INFO 139712694728512] Epoch[187] Batch [5]#011Speed: 183.65 samples/sec#011loss=1.024517\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] Epoch[187] Batch[10] avg_epoch_loss=1.003194\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=187, batch=10 train loss <loss>=0.977605390549\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] Epoch[187] Batch [10]#011Speed: 179.16 samples/sec#011loss=0.977605\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4368.6089515686035, \"sum\": 4368.6089515686035, \"min\": 4368.6089515686035}}, \"EndTime\": 1597164015.758351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164011.389287}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=149.929153272 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=187, train loss <loss>=1.00319354643\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:15 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:16 INFO 139712694728512] Epoch[188] Batch[0] avg_epoch_loss=1.101123\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=188, batch=0 train loss <loss>=1.10112345219\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:18 INFO 139712694728512] Epoch[188] Batch[5] avg_epoch_loss=1.012970\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=188, batch=5 train loss <loss>=1.0129695634\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:18 INFO 139712694728512] Epoch[188] Batch [5]#011Speed: 182.53 samples/sec#011loss=1.012970\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:19 INFO 139712694728512] processed a total of 626 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4025.8989334106445, \"sum\": 4025.8989334106445, \"min\": 4025.8989334106445}}, \"EndTime\": 1597164019.784751, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164015.758435}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:19 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.488894971 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:19 INFO 139712694728512] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=188, train loss <loss>=0.997040706873\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:19 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:20 INFO 139712694728512] Epoch[189] Batch[0] avg_epoch_loss=0.986485\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=189, batch=0 train loss <loss>=0.986484587193\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:22 INFO 139712694728512] Epoch[189] Batch[5] avg_epoch_loss=0.932842\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=189, batch=5 train loss <loss>=0.932842473189\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:22 INFO 139712694728512] Epoch[189] Batch [5]#011Speed: 177.40 samples/sec#011loss=0.932842\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] Epoch[189] Batch[10] avg_epoch_loss=1.053452\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=189, batch=10 train loss <loss>=1.19818366766\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] Epoch[189] Batch [10]#011Speed: 180.35 samples/sec#011loss=1.198184\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4391.142845153809, \"sum\": 4391.142845153809, \"min\": 4391.142845153809}}, \"EndTime\": 1597164024.176518, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164019.784823}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=145.971639505 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=189, train loss <loss>=1.05345210704\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:24 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:25 INFO 139712694728512] Epoch[190] Batch[0] avg_epoch_loss=1.296378\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=190, batch=0 train loss <loss>=1.29637849331\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:26 INFO 139712694728512] Epoch[190] Batch[5] avg_epoch_loss=1.057351\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:26 INFO 139712694728512] #quality_metric: host=algo-1, epoch=190, batch=5 train loss <loss>=1.05735085408\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:26 INFO 139712694728512] Epoch[190] Batch [5]#011Speed: 180.15 samples/sec#011loss=1.057351\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] Epoch[190] Batch[10] avg_epoch_loss=1.074980\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=190, batch=10 train loss <loss>=1.09613595009\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] Epoch[190] Batch [10]#011Speed: 179.38 samples/sec#011loss=1.096136\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4405.272960662842, \"sum\": 4405.272960662842, \"min\": 4405.272960662842}}, \"EndTime\": 1597164028.582292, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164024.176601}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.865304998 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=190, train loss <loss>=1.07498044317\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:28 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:29 INFO 139712694728512] Epoch[191] Batch[0] avg_epoch_loss=1.044551\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=191, batch=0 train loss <loss>=1.04455065727\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:31 INFO 139712694728512] Epoch[191] Batch[5] avg_epoch_loss=1.050847\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=191, batch=5 train loss <loss>=1.05084749063\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:31 INFO 139712694728512] Epoch[191] Batch [5]#011Speed: 178.38 samples/sec#011loss=1.050847\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] Epoch[191] Batch[10] avg_epoch_loss=1.076939\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=191, batch=10 train loss <loss>=1.10824824572\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] Epoch[191] Batch [10]#011Speed: 179.56 samples/sec#011loss=1.108248\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] processed a total of 662 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4461.171865463257, \"sum\": 4461.171865463257, \"min\": 4461.171865463257}}, \"EndTime\": 1597164033.044041, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164028.582379}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.387347929 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=191, train loss <loss>=1.07693874294\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] Epoch[192] Batch[0] avg_epoch_loss=1.137347\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=192, batch=0 train loss <loss>=1.13734698296\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:35 INFO 139712694728512] Epoch[192] Batch[5] avg_epoch_loss=1.076685\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=192, batch=5 train loss <loss>=1.07668491205\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:35 INFO 139712694728512] Epoch[192] Batch [5]#011Speed: 182.26 samples/sec#011loss=1.076685\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:37 INFO 139712694728512] processed a total of 591 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4048.314094543457, \"sum\": 4048.314094543457, \"min\": 4048.314094543457}}, \"EndTime\": 1597164037.092875, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164033.044128}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:37 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=145.981830138 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:37 INFO 139712694728512] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=192, train loss <loss>=1.01706205606\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:37 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:37 INFO 139712694728512] Epoch[193] Batch[0] avg_epoch_loss=1.154598\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=193, batch=0 train loss <loss>=1.15459787846\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:39 INFO 139712694728512] Epoch[193] Batch[5] avg_epoch_loss=1.054968\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=193, batch=5 train loss <loss>=1.054968069\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:39 INFO 139712694728512] Epoch[193] Batch [5]#011Speed: 181.60 samples/sec#011loss=1.054968\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:41 INFO 139712694728512] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4060.5030059814453, \"sum\": 4060.5030059814453, \"min\": 4060.5030059814453}}, \"EndTime\": 1597164041.153965, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164037.092971}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:41 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.005639861 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:41 INFO 139712694728512] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=193, train loss <loss>=1.07903943658\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:41 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:42 INFO 139712694728512] Epoch[194] Batch[0] avg_epoch_loss=0.867496\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:42 INFO 139712694728512] #quality_metric: host=algo-1, epoch=194, batch=0 train loss <loss>=0.867496132851\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:43 INFO 139712694728512] Epoch[194] Batch[5] avg_epoch_loss=1.096619\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=194, batch=5 train loss <loss>=1.09661877155\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:43 INFO 139712694728512] Epoch[194] Batch [5]#011Speed: 180.86 samples/sec#011loss=1.096619\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] Epoch[194] Batch[10] avg_epoch_loss=1.084570\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=194, batch=10 train loss <loss>=1.07011108398\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] Epoch[194] Batch [10]#011Speed: 179.31 samples/sec#011loss=1.070111\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4427.189111709595, \"sum\": 4427.189111709595, \"min\": 4427.189111709595}}, \"EndTime\": 1597164045.581731, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164041.154059}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.947361165 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=194, train loss <loss>=1.08456982266\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:45 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:46 INFO 139712694728512] Epoch[195] Batch[0] avg_epoch_loss=1.030645\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=195, batch=0 train loss <loss>=1.03064501286\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:48 INFO 139712694728512] Epoch[195] Batch[5] avg_epoch_loss=1.105498\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:48 INFO 139712694728512] #quality_metric: host=algo-1, epoch=195, batch=5 train loss <loss>=1.1054983139\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:48 INFO 139712694728512] Epoch[195] Batch [5]#011Speed: 179.83 samples/sec#011loss=1.105498\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] Epoch[195] Batch[10] avg_epoch_loss=1.083939\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=195, batch=10 train loss <loss>=1.05806722641\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] Epoch[195] Batch [10]#011Speed: 182.01 samples/sec#011loss=1.058067\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] processed a total of 708 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4781.664133071899, \"sum\": 4781.664133071899, \"min\": 4781.664133071899}}, \"EndTime\": 1597164050.363912, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164045.581816}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.06158305 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=195, train loss <loss>=1.12307796876\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:50 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:51 INFO 139712694728512] Epoch[196] Batch[0] avg_epoch_loss=0.858487\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=196, batch=0 train loss <loss>=0.858487010002\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:52 INFO 139712694728512] Epoch[196] Batch[5] avg_epoch_loss=0.974821\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:52 INFO 139712694728512] #quality_metric: host=algo-1, epoch=196, batch=5 train loss <loss>=0.974821339051\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:52 INFO 139712694728512] Epoch[196] Batch [5]#011Speed: 179.77 samples/sec#011loss=0.974821\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] Epoch[196] Batch[10] avg_epoch_loss=0.908498\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=196, batch=10 train loss <loss>=0.828909355402\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] Epoch[196] Batch [10]#011Speed: 177.46 samples/sec#011loss=0.828909\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4435.835123062134, \"sum\": 4435.835123062134, \"min\": 4435.835123062134}}, \"EndTime\": 1597164054.800312, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164050.364004}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=144.95167988 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=196, train loss <loss>=0.90849771012\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:54 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:55 INFO 139712694728512] Epoch[197] Batch[0] avg_epoch_loss=0.882081\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=197, batch=0 train loss <loss>=0.882080972195\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:57 INFO 139712694728512] Epoch[197] Batch[5] avg_epoch_loss=0.997323\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=197, batch=5 train loss <loss>=0.997322966655\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:57 INFO 139712694728512] Epoch[197] Batch [5]#011Speed: 180.70 samples/sec#011loss=0.997323\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] Epoch[197] Batch[10] avg_epoch_loss=0.916138\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=197, batch=10 train loss <loss>=0.818716937304\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] Epoch[197] Batch [10]#011Speed: 180.12 samples/sec#011loss=0.818717\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] processed a total of 665 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4395.49994468689, \"sum\": 4395.49994468689, \"min\": 4395.49994468689}}, \"EndTime\": 1597164059.196328, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164054.8004}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.28679511 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] #quality_metric: host=algo-1, epoch=197, train loss <loss>=0.916138407859\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:40:59 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:00 INFO 139712694728512] Epoch[198] Batch[0] avg_epoch_loss=0.927379\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=198, batch=0 train loss <loss>=0.927379310131\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:01 INFO 139712694728512] Epoch[198] Batch[5] avg_epoch_loss=1.009522\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=198, batch=5 train loss <loss>=1.00952211022\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:01 INFO 139712694728512] Epoch[198] Batch [5]#011Speed: 180.24 samples/sec#011loss=1.009522\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:03 INFO 139712694728512] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4052.865982055664, \"sum\": 4052.865982055664, \"min\": 4052.865982055664}}, \"EndTime\": 1597164063.249713, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164059.196414}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:03 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.180644736 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:03 INFO 139712694728512] #progress_metric: host=algo-1, completed 49 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:03 INFO 139712694728512] #quality_metric: host=algo-1, epoch=198, train loss <loss>=1.09367516637\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:03 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:04 INFO 139712694728512] Epoch[199] Batch[0] avg_epoch_loss=0.823682\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=199, batch=0 train loss <loss>=0.823682308197\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:05 INFO 139712694728512] Epoch[199] Batch[5] avg_epoch_loss=0.953760\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:05 INFO 139712694728512] #quality_metric: host=algo-1, epoch=199, batch=5 train loss <loss>=0.953760455052\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:05 INFO 139712694728512] Epoch[199] Batch [5]#011Speed: 181.91 samples/sec#011loss=0.953760\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] Epoch[199] Batch[10] avg_epoch_loss=0.929314\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=199, batch=10 train loss <loss>=0.899978268147\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] Epoch[199] Batch [10]#011Speed: 181.19 samples/sec#011loss=0.899978\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4379.093885421753, \"sum\": 4379.093885421753, \"min\": 4379.093885421753}}, \"EndTime\": 1597164067.629385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164063.249806}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=155.278937343 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] #quality_metric: host=algo-1, epoch=199, train loss <loss>=0.929314006459\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:07 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:08 INFO 139712694728512] Epoch[200] Batch[0] avg_epoch_loss=1.084446\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=200, batch=0 train loss <loss>=1.08444571495\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:10 INFO 139712694728512] Epoch[200] Batch[5] avg_epoch_loss=1.068774\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=200, batch=5 train loss <loss>=1.06877369682\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:10 INFO 139712694728512] Epoch[200] Batch [5]#011Speed: 182.41 samples/sec#011loss=1.068774\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:11 INFO 139712694728512] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4049.7639179229736, \"sum\": 4049.7639179229736, \"min\": 4049.7639179229736}}, \"EndTime\": 1597164071.679664, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164067.62947}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:11 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.300153439 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:11 INFO 139712694728512] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:11 INFO 139712694728512] #quality_metric: host=algo-1, epoch=200, train loss <loss>=0.986734116077\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:11 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:12 INFO 139712694728512] Epoch[201] Batch[0] avg_epoch_loss=0.971073\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=201, batch=0 train loss <loss>=0.971072673798\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:14 INFO 139712694728512] Epoch[201] Batch[5] avg_epoch_loss=0.941566\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=201, batch=5 train loss <loss>=0.941565781832\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:14 INFO 139712694728512] Epoch[201] Batch [5]#011Speed: 181.39 samples/sec#011loss=0.941566\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:15 INFO 139712694728512] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3995.2151775360107, \"sum\": 3995.2151775360107, \"min\": 3995.2151775360107}}, \"EndTime\": 1597164075.675534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164071.679759}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:15 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=159.935882436 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:15 INFO 139712694728512] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=201, train loss <loss>=0.949440979958\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:15 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:16 INFO 139712694728512] Epoch[202] Batch[0] avg_epoch_loss=0.883315\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=202, batch=0 train loss <loss>=0.883315145969\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:18 INFO 139712694728512] Epoch[202] Batch[5] avg_epoch_loss=0.959714\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=202, batch=5 train loss <loss>=0.959713707368\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:18 INFO 139712694728512] Epoch[202] Batch [5]#011Speed: 180.11 samples/sec#011loss=0.959714\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] Epoch[202] Batch[10] avg_epoch_loss=1.027613\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=202, batch=10 train loss <loss>=1.10909159184\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] Epoch[202] Batch [10]#011Speed: 178.26 samples/sec#011loss=1.109092\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4437.752962112427, \"sum\": 4437.752962112427, \"min\": 4437.752962112427}}, \"EndTime\": 1597164080.113853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164075.675628}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=145.339704444 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=202, train loss <loss>=1.02761274576\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] Epoch[203] Batch[0] avg_epoch_loss=0.903475\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:20 INFO 139712694728512] #quality_metric: host=algo-1, epoch=203, batch=0 train loss <loss>=0.903474748135\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:22 INFO 139712694728512] Epoch[203] Batch[5] avg_epoch_loss=0.970605\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=203, batch=5 train loss <loss>=0.970605144898\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:22 INFO 139712694728512] Epoch[203] Batch [5]#011Speed: 180.43 samples/sec#011loss=0.970605\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] Epoch[203] Batch[10] avg_epoch_loss=1.003135\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=203, batch=10 train loss <loss>=1.04217169285\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] Epoch[203] Batch [10]#011Speed: 179.01 samples/sec#011loss=1.042172\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4402.292013168335, \"sum\": 4402.292013168335, \"min\": 4402.292013168335}}, \"EndTime\": 1597164084.516703, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164080.113939}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=153.552016658 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] #quality_metric: host=algo-1, epoch=203, train loss <loss>=1.00313539397\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:24 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:25 INFO 139712694728512] Epoch[204] Batch[0] avg_epoch_loss=1.095183\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:25 INFO 139712694728512] #quality_metric: host=algo-1, epoch=204, batch=0 train loss <loss>=1.09518265724\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:27 INFO 139712694728512] Epoch[204] Batch[5] avg_epoch_loss=1.132584\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:27 INFO 139712694728512] #quality_metric: host=algo-1, epoch=204, batch=5 train loss <loss>=1.13258386652\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:27 INFO 139712694728512] Epoch[204] Batch [5]#011Speed: 181.16 samples/sec#011loss=1.132584\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:28 INFO 139712694728512] processed a total of 632 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4015.9919261932373, \"sum\": 4015.9919261932373, \"min\": 4015.9919261932373}}, \"EndTime\": 1597164088.533294, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164084.516786}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:28 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=157.366919822 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:28 INFO 139712694728512] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:28 INFO 139712694728512] #quality_metric: host=algo-1, epoch=204, train loss <loss>=1.12465781569\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:28 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:29 INFO 139712694728512] Epoch[205] Batch[0] avg_epoch_loss=1.107947\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:29 INFO 139712694728512] #quality_metric: host=algo-1, epoch=205, batch=0 train loss <loss>=1.10794746876\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:31 INFO 139712694728512] Epoch[205] Batch[5] avg_epoch_loss=1.046718\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:31 INFO 139712694728512] #quality_metric: host=algo-1, epoch=205, batch=5 train loss <loss>=1.04671797156\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:31 INFO 139712694728512] Epoch[205] Batch [5]#011Speed: 180.24 samples/sec#011loss=1.046718\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] Epoch[205] Batch[10] avg_epoch_loss=1.067479\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=205, batch=10 train loss <loss>=1.09239122868\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] Epoch[205] Batch [10]#011Speed: 180.58 samples/sec#011loss=1.092391\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] processed a total of 687 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4376.471042633057, \"sum\": 4376.471042633057, \"min\": 4376.471042633057}}, \"EndTime\": 1597164092.910365, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164088.533362}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=156.971847953 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] #quality_metric: host=algo-1, epoch=205, train loss <loss>=1.06747854298\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:32 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:33 INFO 139712694728512] Epoch[206] Batch[0] avg_epoch_loss=1.141160\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:33 INFO 139712694728512] #quality_metric: host=algo-1, epoch=206, batch=0 train loss <loss>=1.14116024971\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:35 INFO 139712694728512] Epoch[206] Batch[5] avg_epoch_loss=1.000358\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:35 INFO 139712694728512] #quality_metric: host=algo-1, epoch=206, batch=5 train loss <loss>=1.00035795569\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:35 INFO 139712694728512] Epoch[206] Batch [5]#011Speed: 182.26 samples/sec#011loss=1.000358\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:36 INFO 139712694728512] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 3984.1370582580566, \"sum\": 3984.1370582580566, \"min\": 3984.1370582580566}}, \"EndTime\": 1597164096.894988, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164092.910434}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:36 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.357125303 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:36 INFO 139712694728512] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:36 INFO 139712694728512] #quality_metric: host=algo-1, epoch=206, train loss <loss>=1.02844772935\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:36 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:37 INFO 139712694728512] Epoch[207] Batch[0] avg_epoch_loss=1.069785\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:37 INFO 139712694728512] #quality_metric: host=algo-1, epoch=207, batch=0 train loss <loss>=1.0697851181\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:39 INFO 139712694728512] Epoch[207] Batch[5] avg_epoch_loss=1.012930\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:39 INFO 139712694728512] #quality_metric: host=algo-1, epoch=207, batch=5 train loss <loss>=1.01292967796\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:39 INFO 139712694728512] Epoch[207] Batch [5]#011Speed: 180.24 samples/sec#011loss=1.012930\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:40 INFO 139712694728512] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4002.8579235076904, \"sum\": 4002.8579235076904, \"min\": 4002.8579235076904}}, \"EndTime\": 1597164100.898526, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164096.895078}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:40 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=159.380739105 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:40 INFO 139712694728512] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:40 INFO 139712694728512] #quality_metric: host=algo-1, epoch=207, train loss <loss>=1.05649433136\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:40 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:41 INFO 139712694728512] Epoch[208] Batch[0] avg_epoch_loss=0.911082\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:41 INFO 139712694728512] #quality_metric: host=algo-1, epoch=208, batch=0 train loss <loss>=0.911081910133\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:43 INFO 139712694728512] Epoch[208] Batch[5] avg_epoch_loss=1.003631\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:43 INFO 139712694728512] #quality_metric: host=algo-1, epoch=208, batch=5 train loss <loss>=1.00363091628\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:43 INFO 139712694728512] Epoch[208] Batch [5]#011Speed: 180.79 samples/sec#011loss=1.003631\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] Epoch[208] Batch[10] avg_epoch_loss=0.985198\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=208, batch=10 train loss <loss>=0.963079190254\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] Epoch[208] Batch [10]#011Speed: 180.14 samples/sec#011loss=0.963079\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4411.577939987183, \"sum\": 4411.577939987183, \"min\": 4411.577939987183}}, \"EndTime\": 1597164105.310675, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164100.898618}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=146.882392065 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] #quality_metric: host=algo-1, epoch=208, train loss <loss>=0.98519831354\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:45 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:46 INFO 139712694728512] Epoch[209] Batch[0] avg_epoch_loss=0.979575\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:46 INFO 139712694728512] #quality_metric: host=algo-1, epoch=209, batch=0 train loss <loss>=0.979574501514\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:47 INFO 139712694728512] Epoch[209] Batch[5] avg_epoch_loss=0.989294\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:47 INFO 139712694728512] #quality_metric: host=algo-1, epoch=209, batch=5 train loss <loss>=0.989294171333\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:47 INFO 139712694728512] Epoch[209] Batch [5]#011Speed: 176.17 samples/sec#011loss=0.989294\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:49 INFO 139712694728512] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4045.2308654785156, \"sum\": 4045.2308654785156, \"min\": 4045.2308654785156}}, \"EndTime\": 1597164109.356527, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164105.31075}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:49 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=151.531369001 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:49 INFO 139712694728512] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:49 INFO 139712694728512] #quality_metric: host=algo-1, epoch=209, train loss <loss>=0.976792788506\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:49 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:50 INFO 139712694728512] Epoch[210] Batch[0] avg_epoch_loss=0.710557\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:50 INFO 139712694728512] #quality_metric: host=algo-1, epoch=210, batch=0 train loss <loss>=0.710557222366\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:51 INFO 139712694728512] Epoch[210] Batch[5] avg_epoch_loss=0.949544\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:51 INFO 139712694728512] #quality_metric: host=algo-1, epoch=210, batch=5 train loss <loss>=0.949543913205\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:51 INFO 139712694728512] Epoch[210] Batch [5]#011Speed: 181.08 samples/sec#011loss=0.949544\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:53 INFO 139712694728512] processed a total of 617 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4050.175905227661, \"sum\": 4050.175905227661, \"min\": 4050.175905227661}}, \"EndTime\": 1597164113.407291, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164109.356623}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:53 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=152.333942068 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:53 INFO 139712694728512] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:53 INFO 139712694728512] #quality_metric: host=algo-1, epoch=210, train loss <loss>=0.957381415367\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:53 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:54 INFO 139712694728512] Epoch[211] Batch[0] avg_epoch_loss=0.995079\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:54 INFO 139712694728512] #quality_metric: host=algo-1, epoch=211, batch=0 train loss <loss>=0.995078980923\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:55 INFO 139712694728512] Epoch[211] Batch[5] avg_epoch_loss=0.907669\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:55 INFO 139712694728512] #quality_metric: host=algo-1, epoch=211, batch=5 train loss <loss>=0.907669117053\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:55 INFO 139712694728512] Epoch[211] Batch [5]#011Speed: 184.07 samples/sec#011loss=0.907669\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] Epoch[211] Batch[10] avg_epoch_loss=0.944719\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=211, batch=10 train loss <loss>=0.989179229736\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] Epoch[211] Batch [10]#011Speed: 181.85 samples/sec#011loss=0.989179\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4326.855897903442, \"sum\": 4326.855897903442, \"min\": 4326.855897903442}}, \"EndTime\": 1597164117.734762, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164113.407387}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=160.620078394 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] #quality_metric: host=algo-1, epoch=211, train loss <loss>=0.944719168273\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:57 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:58 INFO 139712694728512] Epoch[212] Batch[0] avg_epoch_loss=0.899345\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:41:58 INFO 139712694728512] #quality_metric: host=algo-1, epoch=212, batch=0 train loss <loss>=0.899344563484\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:00 INFO 139712694728512] Epoch[212] Batch[5] avg_epoch_loss=0.935928\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:00 INFO 139712694728512] #quality_metric: host=algo-1, epoch=212, batch=5 train loss <loss>=0.935927708944\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:00 INFO 139712694728512] Epoch[212] Batch [5]#011Speed: 182.26 samples/sec#011loss=0.935928\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:01 INFO 139712694728512] processed a total of 619 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4011.795997619629, \"sum\": 4011.795997619629, \"min\": 4011.795997619629}}, \"EndTime\": 1597164121.747089, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164117.734849}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:01 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=154.289711811 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:01 INFO 139712694728512] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:01 INFO 139712694728512] #quality_metric: host=algo-1, epoch=212, train loss <loss>=0.908469772339\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:01 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:02 INFO 139712694728512] Epoch[213] Batch[0] avg_epoch_loss=0.752335\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:02 INFO 139712694728512] #quality_metric: host=algo-1, epoch=213, batch=0 train loss <loss>=0.752335190773\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:04 INFO 139712694728512] Epoch[213] Batch[5] avg_epoch_loss=0.989036\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:04 INFO 139712694728512] #quality_metric: host=algo-1, epoch=213, batch=5 train loss <loss>=0.98903598388\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:04 INFO 139712694728512] Epoch[213] Batch [5]#011Speed: 182.43 samples/sec#011loss=0.989036\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] Epoch[213] Batch[10] avg_epoch_loss=0.943559\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=213, batch=10 train loss <loss>=0.888986289501\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] Epoch[213] Batch [10]#011Speed: 182.60 samples/sec#011loss=0.888986\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4319.164037704468, \"sum\": 4319.164037704468, \"min\": 4319.164037704468}}, \"EndTime\": 1597164126.06689, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164121.747187}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.127843285 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=213, train loss <loss>=0.943558850072\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] Epoch[214] Batch[0] avg_epoch_loss=0.988285\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:06 INFO 139712694728512] #quality_metric: host=algo-1, epoch=214, batch=0 train loss <loss>=0.988285183907\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:08 INFO 139712694728512] Epoch[214] Batch[5] avg_epoch_loss=1.048264\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:08 INFO 139712694728512] #quality_metric: host=algo-1, epoch=214, batch=5 train loss <loss>=1.04826374849\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:08 INFO 139712694728512] Epoch[214] Batch [5]#011Speed: 180.56 samples/sec#011loss=1.048264\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:10 INFO 139712694728512] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4049.7710704803467, \"sum\": 4049.7710704803467, \"min\": 4049.7710704803467}}, \"EndTime\": 1597164130.117193, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164126.066977}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:10 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=158.028479517 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:10 INFO 139712694728512] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=214, train loss <loss>=1.02592196465\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:10 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:10 INFO 139712694728512] Epoch[215] Batch[0] avg_epoch_loss=1.102163\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:10 INFO 139712694728512] #quality_metric: host=algo-1, epoch=215, batch=0 train loss <loss>=1.10216283798\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:12 INFO 139712694728512] Epoch[215] Batch[5] avg_epoch_loss=0.989595\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:12 INFO 139712694728512] #quality_metric: host=algo-1, epoch=215, batch=5 train loss <loss>=0.989594598611\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:12 INFO 139712694728512] Epoch[215] Batch [5]#011Speed: 178.49 samples/sec#011loss=0.989595\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:14 INFO 139712694728512] processed a total of 601 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4056.7450523376465, \"sum\": 4056.7450523376465, \"min\": 4056.7450523376465}}, \"EndTime\": 1597164134.174496, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164130.117286}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:14 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.143435765 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:14 INFO 139712694728512] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:14 INFO 139712694728512] #quality_metric: host=algo-1, epoch=215, train loss <loss>=1.02223330736\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:14 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:15 INFO 139712694728512] Epoch[216] Batch[0] avg_epoch_loss=1.035300\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:15 INFO 139712694728512] #quality_metric: host=algo-1, epoch=216, batch=0 train loss <loss>=1.03530013561\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:16 INFO 139712694728512] Epoch[216] Batch[5] avg_epoch_loss=1.017639\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:16 INFO 139712694728512] #quality_metric: host=algo-1, epoch=216, batch=5 train loss <loss>=1.01763854424\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:16 INFO 139712694728512] Epoch[216] Batch [5]#011Speed: 179.10 samples/sec#011loss=1.017639\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] Epoch[216] Batch[10] avg_epoch_loss=1.034782\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=216, batch=10 train loss <loss>=1.05535482168\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] Epoch[216] Batch [10]#011Speed: 182.37 samples/sec#011loss=1.055355\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4396.438837051392, \"sum\": 4396.438837051392, \"min\": 4396.438837051392}}, \"EndTime\": 1597164138.571503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164134.17459}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=148.751646351 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] #quality_metric: host=algo-1, epoch=216, train loss <loss>=1.03478230671\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:18 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:19 INFO 139712694728512] Epoch[217] Batch[0] avg_epoch_loss=0.953215\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:19 INFO 139712694728512] #quality_metric: host=algo-1, epoch=217, batch=0 train loss <loss>=0.953214883804\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:21 INFO 139712694728512] Epoch[217] Batch[5] avg_epoch_loss=1.023610\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:21 INFO 139712694728512] #quality_metric: host=algo-1, epoch=217, batch=5 train loss <loss>=1.02361040314\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:21 INFO 139712694728512] Epoch[217] Batch [5]#011Speed: 181.33 samples/sec#011loss=1.023610\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] Epoch[217] Batch[10] avg_epoch_loss=0.954743\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=217, batch=10 train loss <loss>=0.872101122141\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] Epoch[217] Batch [10]#011Speed: 179.17 samples/sec#011loss=0.872101\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] processed a total of 650 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 4400.8469581604, \"sum\": 4400.8469581604, \"min\": 4400.8469581604}}, \"EndTime\": 1597164142.972893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164138.57159}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] #throughput_metric: host=algo-1, train throughput=147.694649346 records/second\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] #progress_metric: host=algo-1, completed 54 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] #quality_metric: host=algo-1, epoch=217, train loss <loss>=0.954742548141\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] loss did not improve\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:22 INFO 139712694728512] Loading parameters from best epoch (177)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 68.1760311126709, \"sum\": 68.1760311126709, \"min\": 68.1760311126709}}, \"EndTime\": 1597164143.041654, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164142.97298}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 INFO 139712694728512] stopping training now\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 INFO 139712694728512] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 INFO 139712694728512] Final loss: 0.902268461206 (occurred at epoch 177)\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 INFO 139712694728512] #quality_metric: host=algo-1, train final_loss <loss>=0.902268461206\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 WARNING 139712694728512] You are using large values for `context_length` and/or `prediction_length`. The following step may take some time. If the step crashes, use an instance with more memory or reduce these two parameters.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 INFO 139712694728512] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 WARNING 139712694728512] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:23 INFO 139712694728512] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 3042.6111221313477, \"sum\": 3042.6111221313477, \"min\": 3042.6111221313477}}, \"EndTime\": 1597164146.085244, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164143.041738}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:26 INFO 139712694728512] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 3616.5809631347656, \"sum\": 3616.5809631347656, \"min\": 3616.5809631347656}}, \"EndTime\": 1597164146.659169, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164146.085379}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:26 INFO 139712694728512] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:26 INFO 139712694728512] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 85.24894714355469, \"sum\": 85.24894714355469, \"min\": 85.24894714355469}}, \"EndTime\": 1597164146.744561, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164146.65926}\n",
      "\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:26 INFO 139712694728512] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[08/11/2020 16:42:26 INFO 139712694728512] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 935380.4359436035, \"sum\": 935380.4359436035, \"min\": 935380.4359436035}, \"setuptime\": {\"count\": 1, \"max\": 9.593963623046875, \"sum\": 9.593963623046875, \"min\": 9.593963623046875}}, \"EndTime\": 1597164146.879011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1597164146.744623}\n",
      "\u001b[0m\n",
      "\n",
      "2020-08-11 16:42:43 Uploading - Uploading generated training model\n",
      "2020-08-11 16:42:43 Completed - Training job completed\n",
      "Training seconds: 994\n",
      "Billable seconds: 994\n",
      "CPU times: user 2.55 s, sys: 119 ms, total: 2.67 s\n",
      "Wall time: 19min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "data_channels = {\n",
    "    \"train\": train_s3\n",
    "}\n",
    "\n",
    "estimator.fit(data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepARPredictor(sagemaker.predictor.RealTimePredictor):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, content_type=sagemaker.content_types.CONTENT_TYPE_JSON, **kwargs)\n",
    "        \n",
    "    def predict(self, ts, cat=None, dynamic_feat=None, \n",
    "                num_samples=100, return_samples=False, quantiles=[\"0.1\", \"0.5\", \"0.9\"]):\n",
    "        \"\"\"Requests the prediction of for the time series listed in `ts`, each with the (optional)\n",
    "        corresponding category listed in `cat`.\n",
    "        \n",
    "        ts -- `pandas.Series` object, the time series to predict\n",
    "        cat -- integer, the group associated to the time series (default: None)\n",
    "        num_samples -- integer, number of samples to compute at prediction time (default: 100)\n",
    "        return_samples -- boolean indicating whether to include samples in the response (default: False)\n",
    "        quantiles -- list of strings specifying the quantiles to compute (default: [\"0.1\", \"0.5\", \"0.9\"])\n",
    "        \n",
    "        Return value: list of `pandas.DataFrame` objects, each containing the predictions\n",
    "        \"\"\"\n",
    "        prediction_time = ts.index[-1] + datetime.timedelta(minutes=10)\n",
    "#         prediction_time = 144\n",
    "        quantiles = [str(q) for q in quantiles]\n",
    "        req = self.__encode_request(ts, cat, dynamic_feat, num_samples, return_samples, quantiles)\n",
    "        res = super(DeepARPredictor, self).predict(req)\n",
    "        return self.__decode_response(res, ts.index.freq, prediction_time, return_samples)\n",
    "    \n",
    "    def __encode_request(self, ts, cat, dynamic_feat, num_samples, return_samples, quantiles):\n",
    "        instance = series_to_dict(ts, cat if cat is not None else None, dynamic_feat if dynamic_feat else None)\n",
    "\n",
    "        configuration = {\n",
    "            \"num_samples\": num_samples,\n",
    "            \"output_types\": [\"quantiles\", \"samples\"] if return_samples else [\"quantiles\"],\n",
    "            \"quantiles\": quantiles\n",
    "        }\n",
    "        \n",
    "        http_request_data = {\n",
    "            \"instances\": [instance],\n",
    "            \"configuration\": configuration\n",
    "        }\n",
    "        \n",
    "        return json.dumps(http_request_data).encode('utf-8')\n",
    "    \n",
    "    def __decode_response(self, response, freq, prediction_time, return_samples):\n",
    "        # we only sent one time series so we only receive one in return\n",
    "        # however, if possible one will pass multiple time series as predictions will then be faster\n",
    "        predictions = json.loads(response.decode('utf-8'))['predictions'][0]\n",
    "        prediction_length = len(next(iter(predictions['quantiles'].values())))\n",
    "#         prediction_index = pd.DatetimeIndex(start=prediction_time, freq=freq, periods=prediction_length)       \n",
    "#         print(prediction_time)\n",
    "#         print(type(prediction_time))\n",
    "#         print(prediction_length)\n",
    "#         print(type(prediction_length))\n",
    "#         print(freq)\n",
    "#         print(type(freq))\n",
    "        \n",
    "        prediction_index = pd.date_range(prediction_time, prediction_time + freq * (prediction_length-1), freq=freq)\n",
    "#         print(prediction_index)\n",
    "        \n",
    "        if return_samples:\n",
    "            dict_of_samples = {'sample_' + str(i): s for i, s in enumerate(predictions['samples'])}\n",
    "        else:\n",
    "            dict_of_samples = {}\n",
    "        return pd.DataFrame(data={**predictions['quantiles'], **dict_of_samples}, index=prediction_index)\n",
    "\n",
    "    def set_frequency(self, freq):\n",
    "        self.freq = freq\n",
    "        \n",
    "def encode_target(ts):\n",
    "    return [x if np.isfinite(x) else \"NaN\" for x in ts]        \n",
    "\n",
    "def series_to_dict(ts, cat=None, dynamic_feat=None):\n",
    "    \"\"\"Given a pandas.Series object, returns a dictionary encoding the time series.\n",
    "\n",
    "    ts -- a pands.Series object with the target time series\n",
    "    cat -- an integer indicating the time series category\n",
    "\n",
    "    Return value: a dictionary\n",
    "    \"\"\"\n",
    "    obj = {\"start\": str(ts.index[0]), \"target\": encode_target(ts)}\n",
    "    if cat is not None:\n",
    "        obj[\"cat\"] = cat\n",
    "    if dynamic_feat is not None:\n",
    "        obj[\"dynamic_feat\"] = dynamic_feat        \n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "# predictor.delete_endpoint()\n",
    "predictor = estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    predictor_cls=DeepARPredictor, \n",
    "    wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-14 23:10:00    60.0\n",
       "2012-03-14 23:20:00    60.0\n",
       "2012-03-14 23:30:00    38.0\n",
       "2012-03-14 23:40:00    36.0\n",
       "2012-03-14 23:50:00    29.0\n",
       "Freq: 10T, Length: 2016, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infs = pd.Series(data[0]['target'][:-144])\n",
    "infs.index=pd.date_range(data[0]['start'], datetime.datetime.strptime(data[0]['start'],  '%Y-%m-%d %H:%M:%S') + datetime.timedelta(minutes=10*2015), freq='10T')\n",
    "infs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predictor.predict(ts= infs, \n",
    "                               dynamic_feat=data[0]['dynamic_feat'],\n",
    "                               quantiles=[0.10, 0.5, 0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2012-03-01 00:00:00    24.0\n",
       "2012-03-01 00:10:00    22.0\n",
       "2012-03-01 00:20:00    20.0\n",
       "2012-03-01 00:30:00    17.0\n",
       "2012-03-01 00:40:00    15.0\n",
       "                       ... \n",
       "2012-03-15 23:10:00    68.0\n",
       "2012-03-15 23:20:00    70.0\n",
       "2012-03-15 23:30:00    50.0\n",
       "2012-03-15 23:40:00    45.0\n",
       "2012-03-15 23:50:00    37.0\n",
       "Freq: 10T, Length: 2160, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "infsf = pd.Series(data[0]['target'])\n",
    "infsf.index=pd.date_range(data[0]['start'], datetime.datetime.strptime(data[0]['start'],  '%Y-%m-%d %H:%M:%S') + datetime.timedelta(minutes=10*2159), freq='10T')\n",
    "infsf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies = infsf['2012-03-15 00:00:00':][infsf['2012-03-15 00:00:00':].values - prediction['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.plot(infsf['2012-03-13 23:20:00':])\n",
    "plt.plot(prediction)\n",
    "plt.fill_between(prediction.index, prediction['0.9'],prediction['0.1'], alpha=0.5)\n",
    "plt.scatter(anomalies.index, anomalies.values, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred2 = prediction.resample('2H').sum()\n",
    "infsf2 = infsf['2012-03-13 23:20:00':].resample('2H').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "anomalies2 = infsf2['2012-03-15 00:00:00':][infsf2['2012-03-15 00:00:00':].values - pred2['0.9'].values > 0]\n",
    "\n",
    "plt.figure(figsize=(20,5))\n",
    "plt.plot(infsf2['2012-03-14 12:00:00':])\n",
    "plt.plot(pred2)\n",
    "plt.scatter(anomalies2.index, anomalies2.values, color='red')\n",
    "plt.fill_between(pred2.index, pred2['0.9'],pred2['0.1'], alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
